{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6: Introduction to Artificial Neural Networks with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is heavily inspired by Andre Guernon work, that can be found here: https://github.com/ageron/handson-ml/blob/master/10_introduction_to_artificial_neural_networks.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "\"\"\"\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"end_to_end_project\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\"\"\"\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  A quick overview of Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.1.0\n",
      "Keras version 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "## Install dependencies\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print('Tensorflow version', tf.__version__)\n",
    "print('Keras version', keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 tf.Tensor - Tensors in Tensorflow\n",
    "\n",
    "What is a tensor? Just a generalization of the concept of vectors beyond the 1-dimensional case. Matrices are 2-dimensional tensors, and so on. You can see Tensorflow's tensors as equivalent to NumPy ndarrays. The main difference is that by default they store 32-bit floating point numbers rather than 64-bit ones. Moreover, Tensorflow's tensors are immutable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[10., 20., 30.],\n",
       "       [40., 50., 60.]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([[10., 20., 30.], [40., 50., 60.]]) # matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 0-dimensional tensor is just a scalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(42) # scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]])\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Tensor Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[2., 3.],\n",
       "       [5., 6.],\n",
       "       [8., 9.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[:, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 1), dtype=float32, numpy=\n",
       "array([[[2.],\n",
       "        [3.]],\n",
       "\n",
       "       [[5.],\n",
       "        [6.]],\n",
       "\n",
       "       [[8.],\n",
       "        [9.]]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[..., 1:3, tf.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Tensor Operations\n",
    "\n",
    "Let's see how we can implement addition, element exponential, and matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[12., 13., 14.],\n",
       "       [15., 16., 17.],\n",
       "       [18., 19., 20.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# addition\n",
    "t + 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[2.7182817e+00, 7.3890562e+00, 2.0085537e+01],\n",
       "       [5.4598152e+01, 1.4841316e+02, 4.0342880e+02],\n",
       "       [1.0966332e+03, 2.9809580e+03, 8.1030840e+03]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# element-wise exponential\n",
    "tf.math.exp(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[1118905.8, 1374813.8, 1630722.9],\n",
       "       [2533879.2, 3113412.5, 3692944.2],\n",
       "       [3948853.5, 4852008.5, 5755165.5]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix exponential. See http://mathworld.wolfram.com/MatrixExponential.html \n",
    "tf.linalg.expm(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 0:** multiply the matrix `t` for its transpose (matrix multiplication)\n",
    "Hint. You can also use the new matrix multiplication operator `@` if you have Python 3.5 or greater (which you should have): https://docs.python.org/3/whatsnew/3.5.html#whatsnew-pep-465"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[ 14.,  32.,  50.],\n",
       "       [ 32.,  77., 122.],\n",
       "       [ 50., 122., 194.]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your solution here: matrix multiplication\n",
    "t @ tf.transpose(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Tensorflow Tensors and NumPy Arrays\n",
    "\n",
    "Coversions are very easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.],\n",
       "       [7., 8., 9.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = t.numpy()\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.],\n",
       "       [7., 8., 9.]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.],\n",
       "       [7., 8., 9.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 tf.Variable\n",
    "\n",
    "A `tf.Variable` object is just a mutable `tf.Tensor`. This can be used to store learned parameters such as connection weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.],\n",
       "       [7., 8., 9.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable(t)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.],\n",
       "       [14., 16., 18.]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign_add(t)\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Tensor Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write value into index index of the TensorArray.\n",
    "array = tf.TensorArray(dtype=tf.float32, size=3)\n",
    "array = array.write(0, tf.constant([1., 2.]))\n",
    "array = array.write(1, tf.constant([3., 10.]))\n",
    "array = array.write(2, tf.constant([5., 7.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 3., 10.], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the value at location index in the TensorArray.\n",
    "array.read(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [5., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the values in the TensorArray as a stacked Tensor.\n",
    "array.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementing MLPs with Keras: an Image Classifier using the Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 Load the Fashion MNIST dataset with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "# There are 10 classes in the Fashion MNIST dataset\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), dtype('uint8'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape, X_train_full.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `imshow()` from matplotlib to display one or more of the images in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train_full[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we perform a rough min-max scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_diff =  255\n"
     ]
    }
   ],
   "source": [
    "X_diff = X_train_full.max() - X_train_full.min()\n",
    "print('X_diff = ', X_diff)\n",
    "X_valid, X_train = X_train_full[:5000]/X_diff, X_train_full[5000:]/X_diff\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 Create a Sequential Model with Keras\n",
    "\n",
    "Now we can just create our Deep Neural Network using the `Sequential` model.\n",
    "\n",
    "**Exercise 1:** complete the sequential model below. You will have to add two hidden `Dense` layers (with 300 and 100 nodes respectively and a suitable activation function) and one `Dense` output layer with an appropriare number of output nodes and an appropriate activation function. \n",
    "If it can help you, check:\n",
    "- `tf.keras` documentation about the `Sequential` class how to use it to build a MLP network: https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
    "- `tf.keras.layers` documentation about the `Dense` layer: https://www.tensorflow.org/api_docs/python/tf/keras/layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the code here:\n",
    "n_net = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]), # this input layer just flattens our 28x28 images\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have correctly initialized your network/model, you can easily get a model’s list of layers, to fetch a layer by its index, or you can fetch it by name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x2237ff61b48>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2237ff61ec8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2237ff5c5c8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x2237ee6c788>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_net.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x2237ff61ec8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_hidden_layer = n_net.layers[1]\n",
    "first_hidden_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_hidden_layer = n_net.get_layer('dense')\n",
    "weights, biases = first_hidden_layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.03071216,  0.06618436,  0.03353794, ...,  0.01598676,\n",
       "         -0.0738664 , -0.01793427],\n",
       "        [-0.02337404, -0.01131349,  0.00668801, ..., -0.04266736,\n",
       "         -0.06821654, -0.04612315],\n",
       "        [-0.01584198,  0.06571612,  0.06933339, ..., -0.01506634,\n",
       "          0.00738184, -0.03254902],\n",
       "        ...,\n",
       "        [-0.05149138,  0.03408103,  0.05431545, ..., -0.06868746,\n",
       "         -0.05314007, -0.02739487],\n",
       "        [-0.02470285,  0.04484378,  0.03313532, ...,  0.0451522 ,\n",
       "          0.03455919, -0.07157749],\n",
       "        [-0.01209525, -0.03432642,  0.06388216, ..., -0.06853902,\n",
       "          0.00169063, -0.07229353]], dtype=float32),\n",
       " (784, 300))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " (300,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases, biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the Dense layer initialized the connection weights randomly and the biases were initialized to zeros, which is fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 Compile the Sequential Model with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have created a model, you must call its `compile()` method to specify the loss function and the optimizer to use. You can also optionally specify a list of extra metrics to compute during training and evaluation.  For a full lists of losses, optimizers and metrics see https://keras.io/losses, https://keras.io/optimizers, and https://keras.io/metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here:\n",
    "\n",
    "n_net.compile(\n",
    "    loss=keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "    metrics=[keras.metrics.sparse_categorical_accuracy]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sparse_categorical_crossentropy` loss is used here because we have sparse labels (i.e., for each instance, there is just a target class index, from 0 to 9 in this case), and the classes are exclusive. On the other hand, if we had one target probability per class for each instance (such as one-hot vectors, e.g. [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.] to represent class 0, and so on upt to class 9), then the `categorical_crossentropy` loss would be used. If we were aiming for binary classification (with one or more binary labels), then we would have chosen the \"sigmoid\" (i.e., logistic) activation function in the output layer rather than the \"softmax\" activation function, and we would have to use the \"binary_crossentropy\" loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 7s 135us/sample - loss: 0.7136 - sparse_categorical_accuracy: 0.7649 - val_loss: 0.5575 - val_sparse_categorical_accuracy: 0.8118\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 6s 110us/sample - loss: 0.4817 - sparse_categorical_accuracy: 0.8323 - val_loss: 0.4399 - val_sparse_categorical_accuracy: 0.8484\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 6s 109us/sample - loss: 0.4353 - sparse_categorical_accuracy: 0.8471 - val_loss: 0.4056 - val_sparse_categorical_accuracy: 0.8614\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 7s 120us/sample - loss: 0.4087 - sparse_categorical_accuracy: 0.8567 - val_loss: 0.3894 - val_sparse_categorical_accuracy: 0.8718\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 6s 112us/sample - loss: 0.3902 - sparse_categorical_accuracy: 0.8635 - val_loss: 0.4016 - val_sparse_categorical_accuracy: 0.8606\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 7s 121us/sample - loss: 0.3741 - sparse_categorical_accuracy: 0.8686 - val_loss: 0.3700 - val_sparse_categorical_accuracy: 0.8730\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 6s 112us/sample - loss: 0.3618 - sparse_categorical_accuracy: 0.8725 - val_loss: 0.3649 - val_sparse_categorical_accuracy: 0.8732\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 7s 121us/sample - loss: 0.3506 - sparse_categorical_accuracy: 0.8762 - val_loss: 0.3518 - val_sparse_categorical_accuracy: 0.8756\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 7s 133us/sample - loss: 0.3405 - sparse_categorical_accuracy: 0.8798 - val_loss: 0.3580 - val_sparse_categorical_accuracy: 0.8754\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 6s 112us/sample - loss: 0.3321 - sparse_categorical_accuracy: 0.8809 - val_loss: 0.3447 - val_sparse_categorical_accuracy: 0.8760\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 7s 120us/sample - loss: 0.3238 - sparse_categorical_accuracy: 0.8843 - val_loss: 0.3465 - val_sparse_categorical_accuracy: 0.8754\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 6s 109us/sample - loss: 0.3166 - sparse_categorical_accuracy: 0.8873 - val_loss: 0.3348 - val_sparse_categorical_accuracy: 0.8796\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 6s 113us/sample - loss: 0.3085 - sparse_categorical_accuracy: 0.8892 - val_loss: 0.3380 - val_sparse_categorical_accuracy: 0.8780\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 6s 118us/sample - loss: 0.3016 - sparse_categorical_accuracy: 0.8915 - val_loss: 0.3379 - val_sparse_categorical_accuracy: 0.8796\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 6s 107us/sample - loss: 0.2955 - sparse_categorical_accuracy: 0.8940 - val_loss: 0.3316 - val_sparse_categorical_accuracy: 0.8836\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 7s 123us/sample - loss: 0.2898 - sparse_categorical_accuracy: 0.8959 - val_loss: 0.3143 - val_sparse_categorical_accuracy: 0.8902\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 6s 113us/sample - loss: 0.2845 - sparse_categorical_accuracy: 0.8977 - val_loss: 0.3198 - val_sparse_categorical_accuracy: 0.8852\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 7s 123us/sample - loss: 0.2784 - sparse_categorical_accuracy: 0.8990 - val_loss: 0.3093 - val_sparse_categorical_accuracy: 0.8898\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 7s 121us/sample - loss: 0.2736 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.3604 - val_sparse_categorical_accuracy: 0.8646\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 6s 109us/sample - loss: 0.2688 - sparse_categorical_accuracy: 0.9029 - val_loss: 0.3046 - val_sparse_categorical_accuracy: 0.8936\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 6s 115us/sample - loss: 0.2644 - sparse_categorical_accuracy: 0.9039 - val_loss: 0.3431 - val_sparse_categorical_accuracy: 0.8694\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 6s 105us/sample - loss: 0.2586 - sparse_categorical_accuracy: 0.9065 - val_loss: 0.3057 - val_sparse_categorical_accuracy: 0.8910\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 6s 111us/sample - loss: 0.2549 - sparse_categorical_accuracy: 0.9083 - val_loss: 0.3059 - val_sparse_categorical_accuracy: 0.8916\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 8s 143us/sample - loss: 0.2497 - sparse_categorical_accuracy: 0.9093 - val_loss: 0.3094 - val_sparse_categorical_accuracy: 0.8870\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 7s 136us/sample - loss: 0.2466 - sparse_categorical_accuracy: 0.9105 - val_loss: 0.2976 - val_sparse_categorical_accuracy: 0.8926\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 8s 148us/sample - loss: 0.2411 - sparse_categorical_accuracy: 0.9141 - val_loss: 0.3050 - val_sparse_categorical_accuracy: 0.8872\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 8s 140us/sample - loss: 0.2375 - sparse_categorical_accuracy: 0.9144 - val_loss: 0.2951 - val_sparse_categorical_accuracy: 0.8914\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 7s 128us/sample - loss: 0.2345 - sparse_categorical_accuracy: 0.9153 - val_loss: 0.2966 - val_sparse_categorical_accuracy: 0.8956\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 6s 115us/sample - loss: 0.2299 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.3056 - val_sparse_categorical_accuracy: 0.8906\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 7s 120us/sample - loss: 0.2265 - sparse_categorical_accuracy: 0.9177 - val_loss: 0.2937 - val_sparse_categorical_accuracy: 0.8968\n"
     ]
    }
   ],
   "source": [
    "history = n_net.fit(\n",
    "    X_train, y_train, epochs=30,\n",
    "    validation_data=(X_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit()` method returns a `History` object that contains:\n",
    "    * the training parameters (`history.params`)\n",
    "    * the list of epochs the model went through while training (`history.epoch`)\n",
    "    * a dictionary containing the loss and other extra metrics that were computed at the end of each epoch (`history.history`)\n",
    "    \n",
    "We can plot the loss and metrics evolutions over the epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAE3CAYAAABhONL2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd5Qb1f338fdVl3allbZ3G/fecKHZrOklJNQktNBJIIGUXyhJICEhQKhJHloCgYRiQgk1BUwxphqMyxp3XLDX3t6LtOrz/DFabdPaa3vtbd/XOXM0MxpJV4PZj+6dO/cqTdMQQgghxMBi6O8CCCGEEKI7CWghhBBiAJKAFkIIIQYgCWghhBBiAJKAFkIIIQYgCWghhBBiAJKAFkIIIQagXgW0UupHSqkVSqmAUuofezn2p0qpCqVUo1LqSaWUtU9KKoQQQgwjva1BlwG/B57c00FKqZOBm4HjgZHAKOC3B1A+IYQQYljqVUBrmvaKpmmvAbV7OfQS4AlN09ZrmlYP3A5cemBFFEIIIYafvr4GPRlY02F7DZCllErr488RQgghhjRTH79fMtDYYbtt3UmX2rdS6mrgagC73X54QUFBnxUiGo1iMEj/t67kvCQm5yUxOS+JyXlJTM5LYns6L1999VWNpmkZPb22rwO6BXB12G5bb+56oKZpjwGPAcyePVtbsWJFnxVi6dKlFBUV9dn7DRVyXhKT85KYnJfE5LwkJuclsT2dF6XUzj29tq9/7qwHpnfYng5Uapq2t2vXQgghhOigt7dZmZRSNsAIGJVSNqVUotr308AVSqlJSikPcAvwjz4rrRBCCDFM9LYGfQvQin4L1UWx9VuUUoVKqRalVCGApmlvAfcA7wM7Y8tv+rzUQgghxBDXq2vQmqbdBtzWw9PJXY59AHjggEolhBBCDHPS5U4IIYQYgCSghRBCiAFIAloIIYQYgCSghRBCiAFIAloIIYQYgCSghRBCiAFIAloIIYQYgCSghRBCiAFIAloIIYQYgCSghRBCiAFIAloIIYQYgCSghRBCiAFIAloIIYQYgCSghRBCiAFIAloIIYQYgHo1H7QQQggxKESjEPJCsMMS8kGwBYI+CPtB0wAt9oi+DnvfnvZdMFkOzfdAAloIIcS+0DQINEFrfaclp2wlrNgOWlQ/Jh6C0e7rWrTDdhSiEYiEIBrWl/h6qMtzIYi0HRPQA7dj+Aa9EG49eN990rckoIUQQuyDaAQiwfYgi4RiYRbqsB5s344EY8d13ReCkB/8Dd0CuH1pAC3SrQjjAb46gO+gDGAwg8EERpP+aDCD0QwGY/fnjBawucCZDZZksDjAkqSvm9vWY4vZETsmCUw2UCr2martwzuvd32ubdviPIAvuO8koIUQoq9oml6jC7TEanUtsXWvvh5q1Wt4IX+HR7++P+FzrRAOxII03B668ZpkbLutCbYv2VLA7tEXmxtSCtq3EyzLVq3jyKOPQQ87gx5oKtbNKb7e9bnYo8EEBukS1ZUEtBBiaIqEYtcfW2PNoG3r3vZrkfEaZLC95tm1dtllfWLZLih7VH+/QHN7+LaF8r6EpTKAyQ5mW/uj2d6+bksBk1WvLRrbapDmDjXLjtuxWmXbusHc/jqjucNzXfZ3Pc4U+1yDcZ9Od8BWoddmRZ+RgBZCHByapodbvAYYW8Jt6wE99Do+H/a31yrblj1th2I1zLbQDbVdk/TptcsDoYwdgq09CJ2hCBjS9ebOpAxIPSzWfJoM1uT2plSrs8t6rHnVbG8PYaO5Q1OqEJ1JQAsxXETCsabTjouvQ9Nq56Vw5zp4/9MOodiaOBy77fe3B25fNb0arbFws+k1SpNdfzTHHu0e/Rqk2Q7mpNh6UoJ9sWuTZru+3qkG2fGap7nHJtflS5dSVFTUN99L9IoWjRJtbiZcV0ekvp5IXR3RVj+mtFSM6emYMjIwut2oPvixo4VChCorCZWWESorI1RWSqisjHB5BQWP/RVlOnSxKQEtxEDTdh0z4W0i3g7XNzveStLceTvQ3P31+1ijHAXwNXowti1tTbFt4WhJAkda5/0mm97T1RhrmjVZYgEYW0zWWM00wfNtgdvxM4zWPr0+GQ0GqX/mWbyffIzr9G+QcsY3UJaD2zNX0zTC5eVooRBaRO+13P0xAtFol0cNlMKU6sGYlo4p1YMym/usXFGfj1BlJeHKSkIVFYQrq4g2N2FMS8eclYkpK0tfMjMx9OE50sJhIg0NeuDW1ROpr4uFbwORujrC9bH9dXWE6+uJ1NdDpHvHtI6U2YwxQw/r+JLecTsTU0YGhiQH4fJyPXzLyzsEsb6Eq6o63F6lM2akY87NJdLcjMnj6bPzsDcS0ELsq0hYv80k0Ny99hmvWfq77+vYCSjY0j2EO4bpvtQ8LR2aVdt6sSZndujB2qH2GG9i1WuW0aiJUJ2XUE0LwZpGQpX1hCqrCZVV4a2sxJGdgymzwx+69Iwuf/DSMVitey2iFgrpf2hrawnX1BKurSFSW064ppZInb5Pi0TwfPs8nCefjDLu2/XP3tA0jebFb1N1332Edu/GlJVF+a9+RfWDD5J22aW4zz0XQ1JSn35mpMVL07/foP655whs2don72l0uzGmp2FKTcOUnqYHd1rbepr+3yotDYPDQbi6mlBFJeHKithjJaHKCsIVlYQqK4k2Nnb/ALMZQt1/zBnd7lhgZ2LOysKU2XE9E0NtLf4NGwjHAjdSV6evtwVuLHwjdXVEEn1ujCElBZPHgzE1FfOIQuwzZmD0eDCmejClpmL0pGJM9WCw2/V/T9XV3ZbQzhJaV6wk0tCw9xNqMmHOzsacm0vSkUdizs3FnJerP+bmYsrJ6dMfJ/tCAloML5qmB6W/AfyN0NpAWs0XsKZSD11/o74EmsDf1P7YcV/Iu++fazB17gTU8VYQR3r7LSLmpM63h3QN2a7XOU32HmuXmqah+XyEa2sJlZYS3L2b0O5SQrs369ulu4lU13R6jbJYMOflYc7PJ+j2kGK1Eq6uJrBhI+HaWn0QiK5fzeXqVGsxOp167ag2FsQ1tT3+oVRWK6a0NIzp6UQaGyj92f9hOewh0n/wfVynn95nzYmta9dS+Ye7aV25Euu4cRQ88TeSjjoK78efUPv441Te9QdqHnkUz0UX4bnowgOuJQW2b6f+uX/S+OqrRL1ebJMmkfXLX2JMcYHBiDIa9E5YRoP+Y8TQ8yORiF67bPtxU1dLpKaWcG0trevXE6mpJert3b9JY3o65qwszAUFOGbPxpSVhTk7C1NWduwxC2WzEW1qitWsqwhX6WEerqrStysr8W/YSKS2tlNNMwO9waXzBxr1YE/1YPSkYh0/Pr5uTPXEg9joSdX3u9371kIwatQen44Gg0RqatrDu6aGqNerf99YEJvS0w/KD8K+IAEtBpa22mnH3rWd7uMMt9+vGel6b2cgHrodA1i/pzO27W+IXRttNxVgXYcdRqt+f6XVpfdmbbvX0uYCa2zbloJmSgKrA2V2dOiF29YBqGtnoAP7X03TNDS/n0hDA5GKesL15XqNJNb8F2mo10Oxvr7Tfi3Y+btiNGLOycGcn0/yscdiiYWxOS8fc36e/scqFvjbly5lVodrrVokoteGYn/o4n/0qtprLq2rVhFpbsbocWNKS8d62CiMs2djSkvvVsMzpqVjSHLErxtqkQjNb79NzaN/oeymm6l++BHSv381Kd/85n4364bKy6n64x9peuPfGNPSyP7db3Gfc078D3Ly/GNInn8MrcXF1Dz+N2oefpjaJ5/E8+3zSL30Usw5Ob3/bxQO07J0KXWLFuFb9hnKbMZ56imkXnABtunT++T6aE+ifn+n1ohwbSyIMjIwZ2frgZSZ0eumfGNKCsaUFBg3rsdjtFBIr63Ggnzjii+YOG9evJZrSvVgcLni/576g8FiwRCrCQ9GEtDi4AgH9jDQQU9LIwR6bvrqqtNofZrSW4UVYFAoewrYU1AOjx6yrjywu/X7OW0p7et2NyvXb2PWUQuJho1EfGHCjS3xjijh+noi5R2a6eq2xPdrra2gFMpqRVmtGCyW+LqyWjCYu2xbYusmk34tMhggGgiiBQJogQDRYACt03b7ereg7Ugp/Q+qR6+BmHNzsU2epNdOPHptxZyXpy/ZWftdK1VGY7yWfDAooxHXqafiPPlkWpYsofqRRyj/1S3UPPwIaVdfRcrZZ/e6qTHq9VLzt79R9+TfQdNI+/73SbvqSozJyQmPt8+YQcHDDxHYupXax/9G3aLnqFv0HClnnEHalVdgHT26x88K19bS8NK/qH/hBcLl5Zhycsj4yU9wn3cuprS0/ToX+8pgs2HJz4P8vEPyeaBf8zV3CL9WmxWXdJ7rUxLQw0TU58P09df4kpNB09A0TQ+0jimXaH8khNbahNZYS7SplmhTHdHmRn3xthD1eYn6Wom2Boj6g0QDYbRgJDZiX4cag2obj0eLDVKg2gcrMBhQygCGNFAZ+j5NQ4tq7Y/RtscoWjSqd57R9nadNgiqCoy1+q94ozHhozUQYHPrg2gJrrsBKJst1hyXijE1FevoURjdHgwuJ0QiRAMdgrVL6GrBIJHGxs4hHAolDG+j04VKt2KwWlCWDs9Zrfq2zao3F8aDN7a4XAO2iW5/KIMB5wknkHz88bR88AE1jzxKxW2/pebRv5B25ZW4zzsXg82W8LVaJELja69R9ac/EamuwXX66WT+7KeY83oXXNYxY8i9+w9kXH8dtf94ioaXXqLxtddwnnA8aVddhX3aNP1zNA3/l19St2gRzW++hRYK4TjyCLJ++QucCxce0p6+YuiSf0WHiKZphMvKaF23Hv/69fjXrSNYUoJ1zBjs06dhnz4d29SpGJ19M5RcpKEB36rV+FaswLdiBf4NG0gLh9nZJ+8OKA2DScNgURgsRgxWEwabDbPLisFhx+BwoOxJetNvW2/d2KNmMKP/KKDTmL1a27pG/BpdT48YDahujwY9vCNRtGik02PiXrP6Y1NZOZmTJrZfF2vriOLx6M10DkdfnTWxD5RSOIuKSD72WLyffErNo49Seccd1Dz2V9IuvwLPd77d6b+N97PPqPzD3QQ2bcI+YwZZDz6IfcaM/fpsc14e2b/6JenX/ID6Z5+l7tlFNL/zLo4jjsCRn8+OBx/Cv349hqQk3N/+Np4Lzt9jLVuI/SEBfRBomqZ3pFi3jtZ16/Cv34B/3Tr9VgEAkwnruLHYpkwhsHULLUuX6vuVwjpmNLZpemDbp8/AOmb0nmtHmgaBZkJfb6B1+af4Vq3Bt34rgd11+lsawZZpIG2iH7u7GYMxVuvseDlMoV9HtTnj11exusDuQsWuwRrcGfriycKQmoNyZeqDLwyBQRY2L11KpjTNDVhKKZKPOZqko4/Ct/wLah55hKq776b2scdIvewyko4+ipqHHqbl/fcx5+aS98D9OE89tU+u+ZpSU8m4/npSL7+ChhdfpO4f/8D52WdEx4wm69e3kvLNb2FM7tue30K0kYDuA6GqKvzr9Fpx63o9kCM1sd6xRiPWsWNJPv447JMnY5syBeu4cZ1uTYk0NdG6di2ta9bgX/MlLe8tofHlVwAwOBzYJozBPiYHe54de3oEY6SS0O7d+LZU4Svx4qs0EmrR/1MqUxRHehDX9CiOEU5so3MwuLPBmc32ai+jJs/R71t1pII9VV+3ew7pDC1C7A+lFEnz5pI0by6+VauoeeRRqh94gOoHHsCQlETG//2M1O99r1e3fe0rY3ISaZdfhueiC/nk5Zc55rvfPaidvoQACej9Eqqswrd8Ob7ln+NdvpzQzhL9CYMB6+jRJM+fj23KZOyTJ2OdMKHH62UAaBpGU5jkkXaSU7Jhqh/tNDOh7Vto3bKb1l01tO5ooHa1We8IBRgsEI31GTI6krGPy8MzdRyOw2dhmz4H5c7Va8Fd/oCULF3KqNlFB+GMCHFoOWbNovBvj9P65Zf4Vqwk5ZtnYEpPP+ifa7BYiOTkSDiLQ0ICuhfC1dV4ly/H9/lyfMuXE9yxAwCD04ljzhw855+Pfdp0bBPG7/l6pa8OKtdBxTqoWAtV66FuR7eey8qRjsUzEstx80jxjATPSKJJefirQrRuKSW4swTbhPE4Zs/GMnp0v97GIER/sk+bFu+4JcRQIwGdQLi2Ft/y5fFQDm7fDoAhORnH7Nm4v/1tHPPmYpswIfH14WgUGna0B3HFWj2YG3e1H5OUCVmTYdoc8BwGsSDGM0K/ttuFAXCMB8f8g/GNhRBCDDQS0DGhqipqH/8bvs+WxYfkMzgc2Gcfjvucs3HMnYtt4sTut09EI1DxJZR/2R7EFev0sZFBv2UobSwUzIM5V0L2FMiaCs6sQ/wNhRBCDCYS0EDzu+9SfsutRH0+HHPm4DrjmyTNm4tt0qTEIxh5a2Dru7DlHdj2nj7IBujDL2ZNgenf1YM4eypkTNSHaBRCCCH2wbAO6KjPR+Uf7qbhxRexTppI3n33YU00tms0CmWrYcvbsPUdKF0FaPpcsONOgTEnQN4scI/s01l3hBBCDF/DNqBb162n7Oc/J7hzJ2lXXkHG9dd3HqfWVwfblsRC+T3w1QAK8mfDwl/qoZwzQwJZCCHEQTHsAlqLRKh98kmq//z/MKWlUfj3v5N0xDz9yYq1sPktPZRLV4AW1e8VHnMCjD0JRh8HSYdmbF0hhBDD27AK6FB5OWU33Yxv+XKcJ59Mzm9vw+h260+uehreuE5fz50JC27QQzl3pj60pBBCCHEIDZuAbnrrLcp/cxtaKETOnXeSctaZ7YMNlH8J//05jCqCsx/XJ7sXQggh+tGQD+hIi5fKO+6g8dVXsU2bRt6992AZMaL9gNYGePF7+pCX5zwBSQd/NCIhhBBib4Z0QLcWF1N6w42ESktJv/Ya0q+5pvNtU5oGr/9QH0Dk0v9JOAshhBgwhmZARyJUP/IINQ8/gjkrixHPPI3j8MO7H7fsYdj0Hzj5Tiicd+jLKYQQQvRgyAV0cHcpngf+SM22bbjOOIPsX9+aeI7lncvgnV/DxDPgiGsPfUGFEEKIPejVTbxKqVSl1KtKKa9SaqdS6oIejlNKqd8rpUqVUo1KqaVKqcl9W+Q9i9TXYaqoIPfee8i7957E4dxSDf+6TB/3+lsPD4k5jYUQQgwtvR1l42EgCGQBFwKP9hC85wGXA/OBVGAZ8EwflLPX7FOnUn3nHaSccUbiA6IReOVKfXjO857Sp2UUQgghBpi9BrRSKgk4B7hV07QWTdM+Bt4ALk5w+GHAx5qmbdc0LQI8C0zqywL3yp4mbP/gbti+FE67D3JkmjohhBADk9I0bc8HKDUT+FTTNHuHfT8HjtU07Ywux44AXgW+C3wN3AGM0zTtzATvezVwNUBWVtbhzz///AF+lXYtLS0kJyd32++pW8W0L39HRfZCNk/4cZ993mDR03kZ7uS8JCbnJTE5L4nJeUlsT+dl4cKFKzVNm93Ta3vTSSwZaOyyrxFIcHGXcuAjYDMQAXYBxyV6U03THgMeA5g9e7ZWVFTUi6L0ztKlS+n2fo274S+XQeYkci5fRM4wnGEq4XkRcl56IOclMTkvicl5SexAzktvrkG3AK4u+1xAc4JjfwPMAQoAG/BbYIlSqn/TMByEly6FSAi+/bRM/yiEEGLA601AfwWYlFJjO+ybDqxPcOx04AVN03ZrmhbWNO0fgIf+uA7d0Tu/ht1fwLcehPQx/VoUIYQQojf2GtCapnmBV4DfKaWSlFJHA98ice/sL4DzlFJZSimDUupiwAxs7ctC75P1r8Hnj8K8a2DyWf1WDCGEEGJf9HagkmuBJ4EqoBa4RtO09UqpQmADMEnTtBLgbiATKAaS0IP5HE3TGvq85L1RsxVe/xHkz4ETf9cvRRBCCCH2R68CWtO0OqBbT+xYKCd32PYDP4wt/Svog5cuAaMZzv07mCz9XSIhhBCi14bcUJ9x/7sBKtfDhf8Cd0F/l0YIIYTYJ0MyoLPL34XNz8KCG2HsCf1dHCGEEGKf9Xaoz8GjYi1jt/wVDjsWim7u79IIIYQQ+2XoBbTZQYN7KpzzBBiM/V0aIYQQYr8MvYBOG83aab+G5Iz+LokQQgix34ZeQAshhBBDgAS0EEIIMQBJQAshhBADkAS0EEIIMQBJQAshhBADkAS0EEIIMQBJQAshhBADkAS0EEIIMQBJQAshhBADkAS0EEIIMQANyYDWNA1N0/q7GEIIIcR+G3IB/em2Gq5b4mNTRXN/F0UIIYTYb0MuoPPdDlpCsKqkvr+LIoQQQuy3IRfQBal2nBZYtbOhv4sihBBC7LchF9BKKca4jayWGrQQQohBbMgFNMBot4HtNV7qvcH+LooQQgixX4ZkQI9xGwEo3iXN3EIIIQanIRnQh7kMGA1KOooJIYQYtIZkQFtNiok5TgloIYQQg9aQDGiAmQUeiksaiERlwBIhhBCDz5AN6Fkj3HiDEb6qlAFLhBBCDD5DN6ALPQCsLpGOYkIIIQafIRvQhakO0pIsch1aCCHEoDRkA1opxcxCjwS0EEKIQWnIBjTo16G3V3tp8MmAJUIIIQaXIR3QMwvkOrQQQojBaUgH9PSCFBmwRAghxKA0pAPaYTExIdspNWghhBCDzpAOaNBvtyreJQOWCCGEGFyGfkCPcNMSCLOlSgYsEUIIMXgM/YCODViyaqc0cwshhBg8hnxAF6Y6SJUBS4QQQgwyQz6glVLMKnRLQAshhBhUhnxAA8ws9MiAJUIIIQaVYRHQ8Ykzdsl1aCGEEIPDsAjotgFLVu+UZm4hhBCDw7AI6LYBS1bJgCVCCCEGiWER0AAzC90yYIkQQohBY9gE9KxCjwxYIoQQYtDoVUArpVKVUq8qpbxKqZ1KqQv2cOwopdR/lFLNSqkapdQ9fVfc/ScDlgghhBhMeluDfhgIAlnAhcCjSqnJXQ9SSlmAd4AlQDaQDzzbN0U9MCPS9AFLVsv90EIIIQaBvQa0UioJOAe4VdO0Fk3TPgbeAC5OcPilQJmmaQ9omubVNM2vadqXfVri/SQDlgghhBhMelODHgdENE37qsO+NUC3GjRwBLBDKfVmrHl7qVJqal8UtC/MLPSwTQYsEUIIMQgoTdtzr2al1HzgJU3Tsjvsuwq4UNO0oi7Hvg0sBL4JvAf8GLgGmKBpWrDLsVcDVwNkZWUd/vzzzx/wl2nT0tJCcnJyt/0bayPc/YWfnx1uZVqGqc8+b7Do6bwMd3JeEpPzkpicl8TkvCS2p/OycOHClZqmze7ptb1JqRbA1WWfC0jUHboV+FjTtDcBlFL3AbcAE9Fr3XGapj0GPAYwe/ZsraioqBdF6Z2lS5eS6P3mBMLcu2Ix4ZQCiorG99nnDRY9nZfhTs5LYnJeEpPzkpicl8QO5Lz0pon7K8CklBrbYd90YH2CY78EBuyNxklWExOyXTJgiRBCiAFvrwGtaZoXeAX4nVIqSSl1NPAt4JkEhz8LHKGUOkEpZQR+AtQAG/uwzAdk1ggZsEQIIcTA19vbrK4F7EAV8E/gGk3T1iulCpVSLUqpQgBN0zYDFwF/AerRg/ybXa8/96e2AUu2VrX0d1GEEEKIHvWqp5SmaXXAmQn2lwDJXfa9gl7jHpDiA5aU1DM+29nPpRFCCCESGzZDfbZpG7BklcxsJYQQYgAbdgGtlGJmgQxYIoQQYmAbdgENMGuEDFgihBBiYBuWAT2z0A3A6l1yu5UQQoiBacgFdIW3gtfqX8MX8vV4zPR8NwYFq+V+aCGEEAPUkAzo95re441tb/R4TNuAJTKzlRBCiIFqyAX09IzpjLCMYNHGRUS1aI/HzRrhprikgagMWCKEEGIAGnIBrZSiyFXEjqYdfFz6cY/HzSzw0BwIs0UGLBFCCDEADbmABpjpmEmmPZNnNzzb4zGzRrQPWCKEEEIMNEMyoI3KyPkTz2dZ+TK21m9NeMxIGbBECCHEADYkAxrg3LHnYjVaeXZj4lp024AlcquVEEKIgWjIBrTb5uaM0Wfwn+3/od6fuJY8a4SHrVUtNPpCh7h0QgghxJ4N2YAGuGjiRQQiAf711b8SPt8+YIk0cwshhBhYhnRAj3aP5qjco3h+0/OEIt1ryW0DlqySAUuEEEIMMEM6oEGvRVe1VvH2zre7PZdkNTFeBiwRQggxAA35gD4672hGukbyzIZn0LTug5LMKpQBS4QQQgw8Qz6gDcrARRMvYn3tetZUr+n2/KxCfcCSrdUyYIkQQoiBY8gHNMAZo8/AaXHyzIZnuj0XH7BE7ocWQggxgAyLgHaYHZw77lzeLXmXspayTs+NTHPgcZhlRDEhhBADyrAIaIDzx5+PQvH8puc77VdKMbPQIz25hRBCDCjDJqBzknM4YcQJ/GvLv7rNFT2r0C0DlgghhBhQhk1Ag37LVXOwudtc0bMK9evQMmCJEEKIgWJYBfT0jOlMTZ/aba7o6QUyYIkQQoiBZVgFtFKKiyZe1G2uaBmwRAghxEAzrAIa4MSRJyacK3pWoZviXTJgiRBCiIFh2AW02WBOOFf0zEIPzf4wH3xV3Y+lE0IIIXTDLqAh8VzRJ07KYmxmMt9/ZiX/W1vej6UTQgghhmlAJ5orOsVu5qUfHMm0/BR++Nwqnl62o1/LKIQQYngblgENieeKdjssPHvlPI6fkMWvX1/PfYs3J5xgQwghhDjYhm1At80V/c9N/+w0V7TNbOQvF83i/LkFPPT+Vm56+UvCkege3kkIIYToe8M2oEGvRVe3VrN45+JO+01GA3eeNZUfHz+WF1fs5upnVtIajPRTKYUQQgxHwzqg2+aKfnbDs92aspVS/PTEcfz+zCks3VzFBX/7jHpvsJ9KKoQQYrgZ1gHdca7o4urihMdcdMQIHrnwcNaXNXHOXz5ld70v4XFCCCFEXxrWAQ17niu6zSlTsnn2innUNAc4+5FP2VjedAhLKIQQYjga9gHdNlf0eyXvdZsruqO5h6Xy0g+OwqAU3/7rMj7bXnsISymEEGK4GfYBDXDBhAtQKP656Z97PG58tpOXrz2KLJeN7z2xXAY0EUIIcdBIQAPZSdmcOOJEXv7qZWpb91wzznPb+dcPjmRKnosfPreKZ5btOJe8JaYAACAASURBVCRlFEIIMbxIQMdcNuUy/BE/Z79xNu/sfGePx7odFhZdeQTHT8jk1tfXc+/iTURkkg0hhBB9SAI6ZlLaJF74xgtkJ2Xzs6U/4+cf/Jw6f12Px9stRv5y0eF8d04BD7+/jVP+9CFvri2X2bCEEEL0CQnoDsZ6xrLotEVcP/N63it5j7NeP2uPtWmT0cBdZ0/l4QtmEdU0rlm0ijMe+pj3N1XJEKFCCCEOiAR0FyaDiaumXcWL33gxXpu+4YMb4pNqdKWU4vRpOSz+yQLuP286Tf4Ql/3jC879yzI+3VZziEsvhBBiqJCA7sFYz1iePe1Zrpt5He+WvMuZr5+519r0OYfn897PirjjrCmU1rdyweOfc8Hjn7GqJHG4CyGEED2RgN4Ds8HM1dOu7nVtGsBiMnDhvBEsvaGIW78xic0VzZz9yKdc/o8vWFfaeAhLL4QQYjCTgO6Ffa1Ngz4r1hXHHMaHNy7khpPHs2JHHd948GOuXbSSrVXNh6jkQgghBqteBbRSKlUp9apSyquU2qmUuqAXr1milNKUUqYDL2b/a6tNv/CNF8hyZPWqNg2QZDXxw4Vj+Oim47j+uDF8sLmak/74IT97oZidtd5DVHohhBCDTW9r0A8DQSALuBB4VCk1uaeDlVIXAkMimLsa5xnHotMX8aMZP4rXphfvWExU2/Oc0Sl2Mz87aTwf3XQcV80fxf/WlXPc/R9wyZPLeW11Kb5g+BB9AyGEEIPBXkNUKZUEnANM0TStBfhYKfUGcDFwc4LjU4DfAN8DlvVtcQcGs8HM96d/n6KCIm795FZ+/sHPybRnsrBwIccVHsecrDmYjeaEr01NsvCL0yZyxTGH8Y9Pd/B6cRk/eaEYh8XIKZOzOXNmHkeNTsNkTPzbSdM0/BE/dpP9YH5FIYQQ/aw3tdxxQETTtK867FsDHNvD8XcCjwIVB1i2AW986ngWnb6IxTsWs6RkCW9se4MXNr+A0+xkQcECjis4jmPyjsFhdnR7babLxo2nTODnJ43nix11vFZcyn++LOeV1aVkOK18c3ouZ83MY0J2Etsat7GyciWrqlaxqnIV1a3VnDP2HH56+E9Jsab0wzcXQghxsKm9DaihlJoPvKRpWnaHfVcBF2qaVtTl2NnA34DZQD7wNWDWNK1b+61S6mrgaoCsrKzDn3/++QP7Jh20tLSQnJzcZ+/XW8FokM3+zXzp+5K1rWvxRr2YMDHBPoFpjmlMsU/BaXT2/PqIxuqqAB/UfM02/zYMjh2YHDvB4AfAbXQz2joam8HGspZlOAwOvuX5FvOS5qGU2mv5+uu8DHRyXhKT85KYnJfE5LwktqfzsnDhwpWaps3u6bW9CeiZwCeapjk67Ps/oEjTtDM67DMAnwE3aJr2gVJqJHsI6I5mz56trVixYo/l2BdLly6lqKioz95vf4SjYVZXrWZJyRLeK3mPcm85BmVgZuZMji88nuMKjyMvOY/mYDPFVcXx2vG6mnUEo0EA0iwFRHwjKa/MJeIbyZyC0Zw1M4/TpuRQ4d/O7Z/dzprqNczKnMWtR9zKGM+YPZZpIJyXgUjOS2JyXhKT85KYnJfE9nRelFJ7DOjeNHF/BZiUUmM1TdsS2zcdWN/lOBd6zfmFWG3OGNu/Wyl1nqZpH/Xis4YMk8HEnOw5zMmew41zbmRT3SbeK3mPJbuWcM8X93DPF/eQm5RLha+CqBbFqIxMSpvE+RPOZ2bWTGZlzsJj8wCwq87H68WlvLK6lF+8spZfv76Oo0anc8qk2zk+/3Oe2PAQ5/37PC6efDE/mPaDhE3qQgghBpe9BrSmaV6l1CvA75RSVwIzgG8BR3U5tBHI7bBdACwHDgeq+6a4g5NSiolpE5mYNpEfzfwRJU0lLClZwpc1X/It97eYlTWLaenTegzWglQHPzpuLD9cOIZ1pU28saaUtzdUcstr1YCTqQW3kJP1Jn9f93fe+votfjH3FywsXHhov6QQQog+1dtboa4FngSqgFrgGk3T1iulCoENwCRN00ro0DFMKWWLrVburYl7uCl0FXLplEv3+XVKKabmpzA1P4VfnjaRLVUtvL2+grc3VPLFipMw2sdSlf8G179/PTPTj+bO+beS78rr+y8ghBDioOtVQGuaVgecmWB/CZDw6remaTuAvfdcEvtFKcW4LCfjspz86LixlDW08u7GShavn8nKqjdYFX2HU18+gwm2c7h6xqUsGJu99zcVQggxYAzJwUSGo1y3ne8dOZLvHTmSxta5vLb2u/x905/YFHyeH3+0BPXqOUy0j2KXbSdzR6YyNjMZg0F+PwkhxEAlAT0EpdjNXDJ3JpfMfYp3drzP75fdQZ31Ub5qmcHvPhiB9p6TJGMq03LyOWrkYRxxWBZT8lIw9zA4ihBCiENPAnqIO3HkQo7JP4LHvnyMp9Y9hS25GIAoUAwU74CHtjpQERdOcyo5yVmMTs1hSlYhec4s0u3pZCdlk+XI6tW91kIIIfqGBPQwYDfZ+fGsHzO1cSrTj5hOdWs1Vb4qalpr+Lq+jE3VpexsrKCmtZrNjav4ytvMW7s7jy2eac/iiNx5zMmew9zsueQm5/bwaUIIIfqCBPQwYlAG0uxppNnTmJA6IeExja0hVuyo5eOvd7K8ZAdb60qJGmsodezg3973eGPbGwBk2HI4Mm8eR+TMZW72XLKSsg64fIFIgPKWcpqCTYzzjMNmsu39RWJY+8/2//D0+qe5a/5djHaP7u/iCNGnJKBFJyl2M8dPzOb4idnAPPyhCGt2NVC8q4FVO+tYVbGRBm0TZUnbeN27mDe2vQZAmiWPudlzKBpxJHNz5pJuT+/0vpqm0RRsotxbTllLGeXecspbyinzllHeUk65t5xaf238eLPBzIzMGczNnsu8nHlMSZ+C2ZB4AhIxPL2+9XVu/eRWNDSufudqnjn1GWnZEUOKBLTYI5vZyLxRacwblQaMBuZQ3thKcUkDK0vqWL57HVtbiqm0buV/rW/yZoke2G5THuM9kzAYW6n2V1DuLccb6jz/tdVoJScph5ykHMaljiMnKYfc5FwcJgfFVcUsr1jOI8WP8HDxw9hNdmZlzWJe9jzm5sxlgmcCRoOxe4HFsPDa1tf49Se/Zl7OPK6beR0/ePcHXP3O1Tx1ylOk2dP6u3hC9AkJaLHPclLs5Ey1c+rUHGAyoch5bK5oZlVJLR/uLGZd3SpqtI3UtX6GFknGSjoZ9iOZ5s5nUuYI5uSNYnxGIWm2tB47np0w4gQAGvwNrKhcwefln7O8YjkPrHwAAKfFyZysOczNmcu87HmMdo/udSc2TdMIRUP4I34C4QCN4UY0TZNOcIPEq1te5Tef/oYjco7g/x33/7CZbDx8/MNc/fbVXPPuNTx58pMkW2TSBjH4SUCLA2Y2GpiSl8KUvBS+d+Qo4GwafSG+LG1gXWkT68oaWVfayNsbfLwNQDk5KfVMzk1hal4KU/JcTMlLIdNp7RaSbpubE0acEA/sal81yyuWs7xiOZ+Xf86SXUsASLOlMS1jGgpFIBKIL20h7I/49X1hfb9G50li/vTSn5iRMYMZmTOYnjGdSWmTsBgtB//kiX3y8lcvc9uy2zg692j+tPBP8X4KMzNncn/R/fx4yY+5bsl1/OXEv2A1Wvv88yPRCDWhmj5/XyESkYAWB0WKw8z8sRnMH5sR39fYGmJDWRPryxpZW6qH9nubKmmbUC092aqHdW4KY7OSGZvpZFRGEjZze1N2hiOD00edzumjTgdgd/Nuvqj4gs8rPmdD7QaMyojNaMNqsuKyuMgwZmA1WbEa9aXtOZvRpm+bbGzYvIGAJ0BxVTHvlrwLgMVgYXL6ZGZkzGB65nSmZ0zvdl1dHFovffUSv1v2O47OO5o/L/xztwBekL+A3x/ze37x0S+44YMbeKDoAUyGvvsTV+2r5qaPbuKLii/Y8vkWfjb7ZwflR4AQbSSgxSGTYjdz5Og0jhzdfo3QGwizsbwpFth6eH+0pYZIVE9tg4LCVAdjMp2x0NaDe3RmEg6LiXxnPvnOfM4ae9Z+l2tp+VKK5hcBUNNaw5qqNRRXF1NcVcyzG5/l7+v/DkCBs6BTLXuMewxRorQEW2gONtMcbKYp2BRfbwm1dNpuW3xhHx2nee3aaqB6GCHXbDCTlZQVv1afm5SrPybn4rT0PM/4UPDi5he5/bPbmZ83nz8u/GOPwXj6qNNpDDRy1/K7uO3T27j96Nv75NLFp2Wf8ouPfkFruJWZjpk8t+k5VlSu4N4F9zLKPeqA31+IRCSgRb9KspqYPTKV2SNT4/sC4Qhf13jZUtnClqoWtlY1s6WyhaWbqwhH24Mt32PXAzvLyZhMPbzHZCbjtO1/b+90ezrHjzie40ccD0AwEmRD7QbWVK+huKqYT8s+5d/b/w2ASZkI72UeGIMykGxOxmlx4rK4cFqcZDuy46HRtam942bX5wKRAFvqt/Dh7g8JRAKdnnNanJ0Cu+N6vjMfl8W1P6djQHhh0wv8/vPfsyB/AX8s+uNeLz1cMPECGgONPLLmEdxWN/83+//2O6TD0TCPFD/C39b+jdHu0dx/7P2UFJdgGGPglo9v4bv//S43z72Zs8acJX0YRJ+TgBYDjtVkZEK2iwnZnUMlFImys9bL1qqWeHhvqWrhk221BMPtA6tku2yMiYV12zI2M5m05H1vjrQYLczI1GvNl0y+BE3T2N2ym+KqYrY1bMNusuO0OLstbWHsMDn6/A+3pmnU+mspbymn1FuqP7aUUu4tZ1fzLj4v/xxf2Bc/XqE4POtwTh55MieMOGFQNdX/c9M/ufPzOynKL+L+ovt73S/gB9N/QH2gnqc2PIXb5ubKqVfu82dX+aq48cMbWVm5krPHns3Nc2/GbrJTQgkL8hfw8jdf5hcf/4LffPobPi37lF8f+etB/UNIDDwS0GLQMBsNjMl0MibTySlT2vdHohq76nx8VdnM1uoWtlbpy4srduELRuLHeRzmWPN4cqcad8fm5r1RSlHgLKDAWdCXX22fKKVIt6eTbk9nasbUbs9rmkZjoJEybxllLWVsrt/M2zve5o7P7+Cu5XcxO2s2J488meMLjx/QtyQt2riIPyz/AwsLFnL/sfdjNva+ZUQpxc1zb6Yh0MCfV/0Zt9XNuePO7fXrPyn9hF9+/Etaw63cecydnDH6jG7HZDgyeOzEx3hy3ZM8tPoh1lav5e4FdzMjc0avP0eIPZGAFoOe0aAYmZ7EyPQkTuqwX9M0yhv9sWbytqWZt9aVU+8LxY+zGWHUlx8xIs3BiLSk2KODkWlJZLtsg27WL6UUbpsbt83NpLRJnDDiBK6dfi1bG7ayeMdiFu9YzO2f3c4dn9/BnOw58bBOtaXu/c0PkWc3PMvdX9zNcQXHcd+x9+1TOLcxKAN3HHMHzcFmbv/sdlwWFyeNPGmPr2lr0n587eOMcY/h/qL7GZXS8zVmgzJw5dQrmZs9lxs/vJFL37qUa2dcyxVTrpD79MUBk4AWQ5ZSily3nVy3nWPHZXR6rrYlEA/uD1ZvImK3sbmymfc2VhGMtDeXW0wGClMdjEjVw3tkuoPCVD288zz2QTMDmFKKsZ6xjPWM5YczfshX9V/Fw/p3y37HHZ/dwdzsufGwdtvcPb5XIBKgyltFpa+SKl8VVT59vW3bG/Iy1j2WyemTmZQ2iYmpE/fpvuSn1z/NvSvu5YTCE7jn2HsOaAQ5s8HMA0UP8P13vs/NH92M0+LkyNwjEx5b6a3kxg9vZFXVKs4Zew43zb0Ju8neq8+ZljGNl854ids/u50HVz/I5+Wfc+cxd/bJELhi+JKAFsNSWrKVtGQrR4xKI9//NUVFcwC9uby8sZWdtb7Y4mVnrY8dtV4+3VZLa6i9ydxoUIxIdTA6M5nRGXpz+eiMJEZnJuM6gI5qB5tSivGp4xmfOp7rZl7H5vrNLN6xmLe+fovblt3G7z/7PfNy5pHZmsmG4g3xAG4L44ZAQ7f3tJvsZDmyyHJk4ba6Ka4u5s0db+qfh2KEawST0yczOU1fJqROwGF2dHufp9Y/xX0r7uPEESdy94K7+2R4V7vJzoPHPchliy/jx+//mCdOeqLbpYGPSz/mlx/9En/Ez13z7+Ibo76xz5/jtDi5e/7dHJV7FHd+fifn/vtcbj/6dooKig74O4jhSQJaiA6MBkW+x0G+x8HRYzo/p2ka1S0BPbBrvOyo9bKtysu2ar2HeSjSfi0702ntFtpjMpPJdtkGVG9fpRQTUicwIXUC18+8no11G+M1609aPkHVK1JtqWQ6MslNymVm5kwyHZnxJcuRRaYjk2RzcrfvVdtay4baDWyo3cD62vV8UfEF/93+X/1zUYxKGRWvZU9Om8yKyhX8edWfOWnESfxhwR/6dOz1FGsKfz3hr1z85sVc+961PHXKU4xyjyIcDfPQ6od4Yt0TjPWM5f5j7+ewlMP2+3OUUpw55kymZ0znpg9v4rol13HBhAsO+T3TmqYR1sIyfv0gJwEtRC8ppch02sh02pgzsvP12nAkSkmdj23Vei/zbdX68lpxKc3+9luxkixGRmUkU5jmiDedF6Y6KExzkJNix9iP17uVUkxKm8SktEn8ZNZP+PeSf3PqwlP3+498mj2N+fnzmZ8/P76v2lfdKbQ/Kf0kPkMawCkjT+Gu+Xf16QAjbTIcGTx+4uNc/ObFXP3O1dx37H38ceUfWVW1inPHnctNc27qsxnUDks5jGdPe5Y/rfoTz2x4hhWVK7hr/l3kJecBeoC23UanoXXqqNj2XNvz4WiY5mAzjYFGmoJNnR7j68FGmgPNNAYbaQo00RRsAmCcZxwzM2cyI3MGMzNnkp2U3SffTxwaEtBC9AGT0cCojGRGZSRz4qT2645tte5tVV62VrewraqF7TVe1pc2snhdRaf7us1GvfZe0CW4C2PrSdZD97+rUgqX0dXnNbAMRwbHOo7l2IJjAf38VPmqWF+7Hm/Iy6mHnXpQwrlNgauAv574Vy576zIufvNiHCYHd8+/m9NGndbnn2UxWrhxzo0ckXMEt35yK+e8cU6fvr9C4bQ4SbGm4LK4SLGmkJucG9+OalHW1qzl1a2v8tym5wDIcmTFA3tG5gzGe8bv8/n2h/3sat5FSVMJJc0l7GzaSUlzCaW1pbz54ZtMTJ3IxLSJTEidQIo1pU+/874IRUJsb9zOloYtbKnfwtaGrWyp30K9v55JaZOYmTkzfi76s5x7IgEtxEHUsdbdcQQ10Gvd5Y1+dtX52Fnno6TOR0mt/lhcUk+Tv/MgKGlJFvI8dvJiHd9y3Xby3LbYo53UJMuAaj7vDaUUWUlZh7Qz1fjU8TxywiMs2riIH874ISNTRh7Uz1uQv4B/nfEv3trxFpFopNN/I4WKb3dc77htVEZcFlc8hF1WV/w+e4PaeyfFcDTM5vrNFFfpo+OtrlrNWzveAvTr81PTp8Zr2NMypuGyuAhGgt1DuKmEnc07qfRWdhpEx2P1UOgqxG10s6pqFf/7+n/x53KTcuNh3RbcGfaMPv13GtWilLaUsrV+azyMt9RvYWfTzvhAQiaDicNSDmNG5gzcVjfratbx1PqneGLdEwCMShml/2jJ0M/DCNeIAfH/kgS0EP3EZDRQkKrXmI9K8HyjL8TOOi8ldXqHtV11Psoa/XxV2czSzdWdOqwBWE2GDuHdHty5bjs5KTZyUuzYLXLrDxCvQR4qGY4MLp508SH7vI5MBlO8c96FEy8EoMJbweqq1fHAfmLtE0S0CAr9Hvua1ppOIZxiTWGEcwSzs2ZT6CpkhHMEI1wjKHAVxAdnWbp0KUVFRdT769lYt5FNdZvYWKs/vlfyXvy9Um2pnWrZI10jiWpRgtEgwYi+BCKBbtuhSIhgtH29MdjI1vqtbG3Y2mlgnrzkPMa6x3Jc4XGMcY9hrGcsI10ju92q1xpuZV3Nuvg5eGfnO7yy5ZV4GadnTI/Xsvtr8hwJaCEGqBSHmWkON9Pyu9/ypGkaDb4QpQ2tlDa0UhZf/JQ2tPL+5mqqmwPdXud2mMl26eGdnWIjx2UjJx7gEuLDRXZSNqcediqnHnYqAL6Qj7U1aymuKqakuYS85Lx4EBe6CvepCdhj83BU7lEcldv+s9Mb8rK5bjMb6zbGQ/sf6/6x16FyE1EorEYrDrOD0e7RnDnmzPgthGPcY0gyJ/XqfewmO3Oy5zAnW7+DI6pF2d6wneLq4viPl/d3vQ+0T57zQNEDh3QkPgloIQYhpRSeJAueJAtT8hL/8QyEI1Q06oFd0einvNFPeaO+Xtbgp3hXA3XeYLfXpdjN5KTYsET8vFX7JZkuG1kuK1lOG9kpNjJdVtKSrP3aoU30LYfZwbyceczLmXdQ3j/JnMSsrFnMypoV3xeMBNnSsIXdzbsxG8xYjBasRmundYvBgsVoaX/OaMakTAel+dmgDIzxjGGMZ0x81Lm2yXNWV61mU90mPFZPn3/unkhACzFEWU3G2MhoPdco/KFIPLwrmvQaeEUsyLeUenlvUxU1LQG6joZqNCgykq1kuaydAjzLZSMrxRa/Nu6wyJ8YkZjFaIk3vQ9UXSfPOdTk/x4hhjGb2RgfJrWrtmuK4UiUmpYglU1+fWkOUNW23hRgV52PlTvrE9bG3Q5z/Dp4Xtviad9OTx58HduEOFQkoIUQe2QyGshO0Zu39yQQjlDdHIg3q7ddGy+tb6Wk1seybbW0BDpfc7TEO7bp178znVYy2pZkK+mxdaf14DRrCjGQSUALIfqE1WSMj8I2O8HzmqbR5A9TWh8L7liA7449frSlmtqWYKd7w9vf2xAP7vTk9gDP6BLoGU4rNrN0chNDgwS0EOKQUEqRYjeTYjczKTfxvMnRqEZDa4jq5oC+tPipaQ5S3RKI7yup7blJHcBpM3WqfScK8kynldQkC6ZBMtmJGJ4koIUQA4bBoEhNspCaZGF8tnOPx4YiUeq8QaqaAtS0BXiHIK9uDrChrInq5kC3pnUApcDj0D8rLclCerKVtGQLaUlWUpMtpCdZYpOq6M+n2M3SzC4OKQloIcSgZDYa9F7jrr2Pn90ajFDTEqCquXOQ17YEqPMGqW0JsrGiidqWII2toYTvYYr9eLARYuyOL8iJXTdvu388161fp7eapIld9A0JaCHEkGe3GOOjtu1NKBKl3hukpiWoh7c3QE1LMB7mG3eUUdboZ2VJPQ2+7mGenmzpENwdB4Kx43GYSXGYcdstWEzSvC72bMAGdCgUYvfu3fj9/n1+bUpKChs3bjwIpRrc5LwkNtjOi81mIz8/H7NZphI8GMxGA5kuG5k91MyXLq2jqEifoas1GKG8sZXyRj9lDa3xwWDKGvzsqPWybHttp9nMOkqyGHE79KZzt8OMx2GJhbe+7bZb9P1JFrKc+gAx0gFueBmwAb17926cTicjR47c5+s+zc3NOJ17vn41HMl5SWwwnRdN06itrWX37t0cdtj+z1ss+oY9Nn3oqIzkHo9p9oeoaPRT0eSnwReioTVEoy9IvS9Egy9EY6u+vqmiicZWfV+inuygj/KW5bKS5dInYGlbbx8wxkZGslVq50PEgA1ov9+/X+EsxFCmlCItLY3q6ur+LoroJafNjNNmZmxW734EappGSyAcC+8Qtd4gVU1+qpoD7YPFNAXYVlVDVXMgYZinJVnIcFpx2cw4bSacNhMue9u6udN+p81Mit0UK6cJu9kof3cHiAEb0ID8IxEiAfn/YmhTSsVDvWAvx0ajGnU+fZS3qqZAPLwrm/1UNwdo9ocob/TzVVWIZn+YptYQPVTO4yxGA5kuKzkpeo0822WLD1TTtp7ptEkt/RAY0AHd35KTk2lpaenvYgghREIGgyI9WR+8ZXLu3o/XNA1fMKKHtT9Esz9Ekz8cD+9mf5iGWOCXN/pZV9rIuxsr8Yei3d4rPdlKdoo1HtremiC7rDtIcVg6XUdPcZhxWk0YZHKVfSYBLYQQw4RSiiSriSSraa9Dt7bRNI2m1jDlTfpMaG3hXdmkT6yyu76VlTvrqfeFeHXr+oTvYVDEOsO1d4pzx7ZddjOuDs3tbY/JVlNsvxmb2TAsW44koHtB0zRuvPFG3nzzTZRS3HLLLXznO9+hvLyc73znOzQ1NREOh3n00Uc56qijuOKKK1ixYgVKKS6//HJ++tOf9vdXEEKI/aKUIiV2e9iE7MQjwAG8u+R9ps85isbWoN4ZLtYhrsEXjHd+a9uu8wbZXu2lwRekqYde7h2ZDKpLgJtIsZtJi7UeZCTrA82kx4aCTU+2kDwExm+XgO6FV155heLiYtasWUNNTQ1z5sxhwYIFPPfcc5x88sn86le/IhKJ4PP5KC4uprS0lHXr1gHQ0NDQz6UXQoiDz2RQ8eFU90UkqneKa/brTez6EqIlEI41v4fi+zo+/3WNlxU76qnzBbtNhwpgMxvizf/6+O2x0eKS9Gb3FLveWS7FbsYVG4J2oN3GNigC+rf/Xs+GsqZeHx+JRDAa93yiJ+W6+M0ZvZuH9OOPP+b888/HaDSSlZXFscceyxdffMGcOXO4/PLLCYVCnHnmmcyYMYNRo0axfft2rrvuOk4//XROOumkXpdbCCGGG6OhfYz2/RGODfla3aIPKFPTrA/9WtO23RJgd72P4l0N1HkDe+wkZzEZYqFt6hTcbUF+7cLRh3SO80ER0P1NS/TzDFiwYAEffvgh//3vf7n44ou54YYb+N73vseaNWtYvHgxDz/8MC+++CJPPvnkIS6xEEIMD6a9DCzTUSSqxZvcm/xhGlv1W9maOjw2+UPx/bUtelN8Y2z/tQtHH4Jv1G5QBHRva7pt+nrgiQULFvDXv/6VSy65hLq6Oj788EPuvfdedu7cSV5eHldddRVer5dVq1Zx2mmnYbFYOOeccxg9ejSXXnppn5VDCCHE/jMaVGwClH1rhgf9lrZDfUl7UAR0fzvrrLNYqYlFkAAAHOtJREFUtmwZ06dPRynFPffcQ3Z2Nk899RT33nsvZrOZ5ORknn76aUpLS7nsssuIRvXbEu66665+Lr0QQogD1R+3iUlA70HbPdBKKe69917uvffeTs9fcsklXHLJJd1et2rVqkNSPiGEEENXr4aCUUqlKqVeVUp5lVI7lVIX9HDcJUqplUqpJqXUbqXUPUop+REghBBC7KPejtX2MBAEsoALgUeVUokuDDuAnwDpwDzgeODnfVBOIYQQYljZa+1WKZUEnANM0TStBfhYKfUGcDFwc8djNU17tMNmqVJqEbCwD8srhBDi/7d359FVVdcDx78HwjwJBjGCBrRghMwQIkSGFEiqIGIAQSYBAZVBlEWNKTKoYGthWRVbKFgEASUpiGJFSsEE5CctCRiNpIjIVIaSkEBGMu/fHy95TeJ7GTDDS7I/a71F3r3n3rPvzsk73PvuPUc1CBW5/NwDyBeRk8WWfQMMqsC2AwGbY78ZY2YBswA6depEVFRUifXt2rUjLS2tAlX8VH5+/k1vW59pXmyri3nJysr6yd9MVUtPT6/2OuoizYttmhfbfk5eKtJBtwZSSi1LAcp8jskYMw3oA8ywtV5E1gHrAPr06SODBw8usf7f//73TT8qVZfm961Jmhfb6mJemjdvjo+PT7XWERUVRem/S6V5sUfzYtvPyUtFOuh0oPQArG0Bu6ccxphRwO+AoSJy9aYiU0oppRqwitwkdhJwMsZ0L7bMC/uXrn8FrAceFpG4nx+iUkop1fCU20GLSAbwEfCKMaaVMSYAeATYXLqsMeaXwFZgtIgcqepgVeXFxsaye/fuGqlrxowZxMfHV3q7qKgoRowYUQ0RKaVU3VXRx6xmAy2ABOBD4BkROW6MucsYk26Muauw3GKgHbC7cHm6Mebzqg+7bsrLK39atapWUx10fn4+7777Lj179qz2uqpTfn5+bYeglFJABTtoEUkWkVEi0kpE7hKRDwqXnxeR1iJyvvB9oIg4FS4rej1YnQdQnTIyMhg+fDheXl64u7sTHh5O165dCQ0NpW/fvvTt25dTp04B8Omnn+Lv74+Pjw9Dhw7lypUrACxbtoxZs2YRFBTElClTOH78OH379sXb2xtPT09++OEHALZs2WJd/tRTT5XZUezZswdfX1+8vLwYMmQIAEeOHKF///74+PjQv39/vv/+e3JycliyZAnh4eF4e3uzY8cOMjIymD59On5+fvj4+PDJJ58AkJmZyWOPPYanpyfjxo3D39+fmJgYAD788EM8PDxwd3cnNDTUGkfr1q1ZsmQJ/v7+HD58mMGDB1u3qWiMFWFvu/z8fBYuXIiHhweenp6sXr0agOjoaPr374+Xlxd9+/YlLS2NjRs3MnfuXOs+R4wYYb2z0sXFpcRxvPLKK/j5+eHu7s6sWbOsk6WcOnWKoUOH4uXlha+vLz/++COTJ0+25hBg4sSJ7Nq1q0LHpZRSZRKRWn/17t1bSouPj//fm92hIhseqvArd31Q+eV2h/6kztK2b98uM2bMsL6/fv26uLq6yvLly0VEZNOmTTJ8+HAREUlOTpaCggIREVm/fr0sWLBARESWLl0qvr6+kpmZKSIic+fOlS1btoiISHZ2tmRmZkp8fLyMGDFCcnJyRETkmWeekU2bNtmMKSEhQbp06SKnT58WEZGkpCQREUlJSZHc3FwREfnHP/4hISEhIiLy3nvvyZw5c0REJDU1VcLCwmTz5s0iInLt2jXp3r27pKeny8qVK2XWrFkiIhIXFyeNGzeW6OhouXjxotx5552SkJAgubm5EhgYKDt37hQREUDCw8OtsQ0aNEiio6MrHWNkZKQ1j7bY2+5Pf/qThISEWNclJSVJdna2dOvWTY4cOVJi2+J5EBEZPny4REZG2jyOonhFRCZNmiS7du0SEZG+ffvKRx99JCIiN27ckIyMDImKipJHHnlERCzto2vXrtZ4qlOJv49qUpQfVZLmxTbNi21l5QWIkTL6Rh2GswweHh4sXLiQ0NBQRowYwYABAwB4/PHHrf8+//zzAFy4cIFx48Zx+fJlcnJy6Natm3U/I0eOpEWLFgD069ePFStWcOHCBUJCQujevTv79+/n6NGj+Pn5AXDjxg1uu+02mzH985//ZODAgdb9d+jQAYCUlBSeeOIJfvjhB4wx5Obm2tx+79697Nq1i1WrVgGW52nPnz/PoUOHmD9/PgDu7u54enoClrPRwYMH07FjR8Byhnjw4EFGjRpF48aNGT16dJXHWJq97fbt28fTTz+Nk5OTtZ64uDhcXFysuWzbtvQDCD9V+jgiIyP5/e9/T2ZmJsnJyfTq1YvBgwdz8eJFHn30UcDymBPAoEGDmDNnDgkJCXz00UeMHj3aGo9SSv0cdeOT5MHfVar4jSp6rrVHjx4cPXqU3bt3ExYWRlBQEGCZPKNI0c/z5s1jwYIFjBw5kqioKJYtW2Yt06pVK+vPEyZMwN/fn88++4zg4GDeffddRIQnnniiQjNfiUiJ+ossXryYwMBAdu7cydmzZ+0+dyci7Nixg3vvvfcny+2Vt6d58+Y0bty4ymOs6Ha26rFXt5OTk3WGMbD8x8TWcWRlZTF79mxiYmK48847WbZsGVlZWWXmYfLkyWzdupVt27bp3N9KqSpT0ZvEGqRLly7RsmVLJk2axMKFC62zVIWHh1v/7devH2A5y+vcuTMAmzZtsrvP06dPc/fdd/Pss88ycuRIvv32W4YMGcL27dtJSEgAIDk5mXPnztncvl+/fhw4cIAzZ85Yy5auf+PGjdbybdq0KTFKVnBwMKtXr7Z2OF9//TUADzzwABEREQDEx8cTF2d5Qs7f358DBw5w9epV8vPz+fDDDxk0qOxB5CobY3nsbRcUFMTatWutN98lJyfj5ubGpUuXiI6OBiyDkOTl5dG1a1diY2MpKCjgP//5D0eO2H7IoKjjdnZ2Jj09ne3btwOWM/EuXbrw8ccfA5CdnU1mZiYAU6dO5c033wSgV6/KzV2ulFL2aAddhri4OOuNWytWrOCll14CLB/O/v7+vPXWW/zhD38ALDeDjR07lgEDBuDs7Gx3n+Hh4bi7u+Pt7c2JEyeYMmUKPXv2ZPny5QQFBeHp6cmwYcO4fPmyze07duzIunXrCAkJwcvLi3HjxgHwwgsvEBYWRkBAQIkbzAIDA4mPj7feJLZ48WJyc3Px9PTE3d2dxYsXAzB79mwSExPx9PTk9ddfx9PTk3bt2uHi4sJvf/tbAgMDrTdHPfLII2XmrbIxlsfedjNmzOCuu+7C09MTLy8vPvjgA5o2bUp4eDjz5s3Dy8uLYcOGkZWVRUBAAN26dbN+beHr62uzrltuuYWZM2fi4eHBqFGjrJfKATZv3szbb7+Np6cn/fv357///S9gGar2vvvuY9q0aRU+JqWUKldZX1DX1Kvcm8QqKTU19aa3LY+rq6skJiZW2/6rU1l5ycvLkxs3boiIyKlTp8TV1VWys7NrKrRa9XPbS0ZGhtx9991y/fr1KoqofHqTWO3RvNimebFNbxJTP1tmZiaBgYHk5uYiIqxZs4amTZvWdlgOb9++fUyfPp0FCxbQrl272g5HKVWPaAddSWfPnq2xuvz9/cnOzi6xbPPmzXh4eFR5XW3atLE+w1xb3nvvPd56660SywICAvjjH/9YSxGVb+jQoZw/f762w1BK1UPaQTuwf/3rX7UdQo2aNm2afo+rlFKF9CYxpZRSygFpB62UUko5IO2glVJKKQekHbRSSinlgLSDriKtW7e2u+7s2bO4u7vXYDRKKaXqOu2glVJKKQdUJx6zev3I65xIPlHh8vn5+TYncSjOrYMboX1D7a4PDQ3F1dWV2bNnA5ahPI0xHDx4kGvXrpGbm8vy5cvLHfaytKysLJ555hliYmJwcnLijTfeIDAwkOPHjzNt2jRycnIoKChgx44d3HHHHTz22GNcuHCB/Px8Fi9ebB02UymlVP1WJzro2jB+/Hiee+45awcdERHBnj17eP7552nbti1Xr17l/vvvZ+TIkTZnT7KnaNCNuLg4Tpw4QVBQECdPnmTt2rXMnz+fiRMnkpOTQ35+Prt37+aOO+7gs88+AyyTRiillGoY6kQHXdaZri1pVTDdpI+PDwkJCVy6dInExETat2+Pi4sLzz//PAcPHqRRo0ZcvHiRK1eucPvtt1d4v4cOHWLevHkAuLm54erqysmTJ23OE21vPmqllFL1n34HXYYxY8awfft2wsPDGT9+PFu3biUxMZGjR48SGxtLp06dSswrXBFiZ17hCRMmsGvXLlq0aEFwcDBffPGFdT5qDw8PwsLCeOWVV6risJRSStUBdeIMuraMHz+emTNncvXqVQ4cOEBERAS33XYbTZo0ITIy0u6czWUZOHAgW7du5Ze//CUnT57k/Pnz3HvvvSXmiT59+jTffvstbm5udOjQgUmTJtG6detKzaGslFKqbtMOugy9evUiLS2Nzp074+LiwsSJE3n44Yfp06cP3t7euLm5VXqfs2fP5umnn8bDwwMnJyc2btxIs2bNCA8PZ8uWLTRp0oTbb7+dJUuWEB0dza9//WsaNWpEkyZNWLNmTTUcpVJKKUekHXQ54uLirD87Oztz+PBhm+XS09Pt7qNr16589913ADRv3tzmmXBYWBhhYWEllgUHBxMcHHwTUSullKrr9DtopZRSygHpGXQViouLY/LkySWWNWvWrMFNG6mUUurn0w66Cnl4eBAbG1vbYSillKoH9BK3Ukop5YC0g1ZKKaUckHbQSimllAPSDloppZRyQNpBV5Gy5oOuL6Kiovjqq69qpK6HHnqI69evV3q7jRs3Mnfu3GqISCmlapZ20HVUXl5ejddZEx20iFBQUMDu3bu55ZZbqrWu6lR0HEopdbPqxGNW/33tNbL/XfH5oPPy80kuZz7oZve5cftvfmN3fVXOB3358mXGjRtHamoqeXl5rFmzhgEDBtC6dWueeuopIiMjad++Pdu2baNjx46sX7+edevWkZOTwy9+8Qs2b95My5YtmTp1Kh06dODrr7/G19eXkSNHMn/+fABrbG3atGHlypVERESQnZ3No48+yssvv2w3tvfff59Vq1ZhjMHT05PNmzfz6aefsnz5cnJycrj11lvZunUrN27cYO3atTRu3JgtW7awevVq3NzcePrppzl//jwAb775JgEBASQmJjJhwgSSkpLw8/Njz549HD16FGdnZ9544w02bNgAwIwZM3juuec4e/YsDz74IIGBgRw+fJiPP/6YQYMGERMTg7Ozc4Vj7NSpU7m/C1vbtWzZkvT0dObNm0dMTAzGGJYuXcro0aPZs2cPv/nNb8jPz8fZ2Zn9+/ezbNkyWrduzcKFCwFwd3fnb3/7G8BPjuN3v/sd0dHR3LhxgzFjxlh/F9HR0cyfP5+MjAyaNWvG/v37eeihh1i9ejXe3t4ABAQEsGbNGjw9Pcs9LqVUPSQitf7q3bu3lBYfH2/9+fKKFXJ20uQKv049PqHcMpdXrPhJncUdO3ZMBg4caH1/3333yblz5yQlJUVERBITE+Wee+6RgoICERFp1aqV3X2tWrVKli9fLiIieXl5kpqaKmKZ1kq2bNkiIiIvv/yyzJkzR0RErl69at120aJF8vbbb4uIyBNPPCHDhw+XvLw8EREZMWKEHDp0SERE0tLSJDc3V/7+97/LzJkzpaCgQPLz82X48OFy4MABERFrvUW+++476dGjhyQmJoqISFJSkoiIJCcnW49r/fr1smDBAhERWbp0qaxcudK6/eOPPy5ffvmliIicO3dO3NzcRERkzpw58tprr4mIyOeffy6AJCYmSkxMjLi7u0t6erqkpaVJz5495dixY3LmzBkxxsjhw4et+3Z1dZXExMRKx/jee+9Z82iLre1SU1PlhRdekPnz55col5CQIF26dJHTp0+XqLt0Hnr16iVnzpyxeRxF2+Tl5cmgQYPkm2++kezsbOnWrZscOXJERERSUlIkNzdXNm7caI3h+++/F1t/F0WK/31Ul8jIyGqvoy7SvNimebGtrLwAMVJG31gnzqDLOtO1xdHmg/bz82P69Onk5uYyatQo6xlSo0aNGDduHACTJk0iJCQEgO+++46XXnqJ69evk56eXmI87rFjx9K48OpAQEAACxYsYOLEiYSEhNClSxf27t3L3r178fHxASxjhP/www8MHDjwJ3F98cUXjBkzBmdnZwA6dOgAwIULFxg3bhyXL18mJyeHbt262Tyuffv2ER8fb32fmppKWloahw4dYufOnQD86le/on379oBlLuxHH32UVq1aARASEsKXX37JyJEjcXV15f7776/yGEuzt92+ffvYtm2btVz79u359NNPGThwoLVMUd1lKX0cERERrFu3jry8PC5fvkx8fDzGGFxcXPDz8wOgbdu2gOV3++qrr7Jy5Uo2bNjA1KlTK3RMSqn6Sb+DLkNVzQc9cOBADh48SOfOnZk8eTLvv/++zXLGGACmTp3KO++8Q1xcHEuXLi1RR1HnBvDiiy/y7rvvcuPGDe6//35OnDiBiBAWFkZsbCyxsbGcOnWKJ5980mZ9ImKts7h58+Yxd+5c4uLi+POf/2z3GAsKCjh8+LC1rosXL9KmTRu7c17bW176uKoyxopuZ6see3U7OTmV+H7Z3u/nzJkzrFq1iv379/Ptt98yfPhwsrKy7O63ZcuWDBs2jE8++YSIiAgmTJhQoWNSStVP2kGXYfz48Wzbto3t27czZswYUlJSbmo+6HPnznHbbbcxc+ZMnnzySY4dOwZYOrjt27cD8MEHH/DAAw8AlisALi4u5ObmsnXrVrv7/fHHH/Hw8CA0NJQ+ffpw4sQJgoOD2bBhg3V2rYsXL5KQkGBz+yFDhhAREUFSUhIAycnJAKSkpNC5c2cANm3aZC3fpk0b0tLSrO+DgoJ45513rO+Lhjl94IEHiIiIAGDv3r1cu3YNsPxH5eOPPyYzM5OMjAx27tzJgAEDysxdZWMsj73tSh/LtWvX6NevHwcOHODMmTMl6u7atav1d3js2DHr+tJSU1Np1aoV7dq148qVK3z++ecAuLm5cenSJaKjowHL77vopr8ZM2bw7LPP4ufnV6EzdqVU/aUddBlszQcdExNDnz592Lp1a4Xng46KisLb2xsfHx927NhhvbGrVatWHD9+nN69e/PFF1+wZMkSAF599VX8/f0ZNmxYmXW8+eabuLu74+XlRYsWLXjwwQcJCgpiwoQJ9OvXDw8PD8aMGVOiUy19fIsWLWLQoEF4eXmxYMECwHJD3NixYxkwYID10jLAww8/zM6dO/H29ubLL7/k7bffJiYmBk9PT3r27MnatWsBWLp0KXv37sXX15fPP/8cFxcX2rRpg6+vL1OnTqVv3774+/szY8YM66X4sn4HlYmxPPa2e+mll7h27Zo1n5GRkXTs2JF169YREhKCl5eX9euI0aNHk5ycjLe3N2vWrKFHjx426/Ly8sLHx4devXoxffp0AgICAGjatCnh4eHMmzcPLy8vhg0bZj0L7927N23btmXatGkVPialVD1V1hfUNfUq7yaxyip9M5SjKuvGsupQU3nJysqS3NxcERH56quvxMvLq0bqvVmO1F4uXrwo3bt3l/z8/DLL6U1itUfzYpvmxbZ6f5OYqlvOnz/PY489RkFBAU2bNmX9+vW1HVKd8P7777No0SLeeOMNGjXSi1tKNXTaQVehys4HXfQ9cXVLSkpiyJAhFBQUlPjg379/P7feemuV19e9e3e+/vrrKt9vZaxYsYK//vWvJZaNHTuWRYsW1VJE5ZsyZQpTpkyp7TCUUg5CO+gq5KjzQd96663ExsZWyeNndcWiRYscujNWSqnyOPR1NCnjsRylGir9u1CqYXDYDrp58+YkJSXph5FSxYgISUlJNG/evLZDUUpVM4e9xN2lSxcuXLhAYmJipbfNysrSDzAbNC+21bW8NG/enC5dutR2GEqpalahDtoY0wH4CxAEXAXCROQDO2WfB0KBFsAO4BkRya5sYE2aNKnw8I2lRUVFlft8bUOkebFN86KUckQVvcT9RyAH6ARMBNYYY3qVLmSMCQZeBIYAXYG7AftTKSmllFLKpnI7aGNMK2A0sFhE0kXkELALmGyj+BPAX0TkuIhcA14FplZhvEoppVSDUJEz6B5AvoicLLbsG+AnZ9CFy74pVa6TMabqH7ZVSiml6rGKfAfdGkgptSwFsPVAbemyRT+3AZKKFzTGzAJmFb5NN8Z8X4FYKsoZy3flqiTNi22aF9s0L7ZpXmzTvNhWVl5cy9qwIh10OtC21LK2gK0ZGEqXLfr5J2VFZB2wrgL1V5oxJkZE+lTHvusyzYttmhfbNC+2aV5s07zY9nPyUpFL3CcBJ2NM92LLvIDjNsoeL1xXvNwVEUmyUVYppZRSdpTbQYtIBvAR8IoxppUxJgB4BNhso/j7wJPGmJ7GmPbAS8DGKoxXKaWUahAq+pjVbCzPNScAH2J5tvm4MeYuY0y6MeYuABHZA/weiATOFb6WVn3Y5aqWS+f1gObFNs2LbZoX2zQvtmlebLvpvBgdSlMppZRyPA47FrdSSinVkGkHrZRSSjmgetVBG2M6GGN2GmMyjDHnjDETajsmR2GMiTLGZBXeM1DVz53XCcaYucaYGGNMtjFmY6l1Q4wxJ4wxmcaYSGNMmc8n1if28mKM6WqMkWJtJt0Ys7gWQ61Rxphmxpi/FH6WpBljvjbGPFhsfYNsM2XlRduM2WKMuWyMSTXGnDTGzCi2rtLtpV510FRwzPAGbK6ItC583VvbwdSCS8ByYEPxhcYYZyxPKiwGOgAxQHiNR1d7bOalmFuKtZtXazCu2uYE/AcYBLTD0j4iCjuhhtxm7OalWJmG2mZ+C3QVkbbASGC5Mab3zbYXh51usrKKjRnuLiLpwCFjTNGY4S/WanDKIYjIRwDGmD5A8fkaQ4DjIvLXwvXLgKvGGDcROVHjgdawMvLSoBU+Yrqs2KK/GWPOAL2BW2mgbaacvBytlaAchIgUHx9ECl/3YMlNpdtLfTqDrsyY4Q3Vb40xV40x/2eMGVzbwTiQEmPIF34A/Yi2nSLnjDEXjDHvFZ4JNEjGmE5YPmeOo23GqlReijTYNmOM+ZMxJhM4AVwGdnOT7aU+ddCVGTO8IQrFMv1nZyzP5X1qjLmndkNyGNp2bLsK+GEZL7g3lnxsrdWIaokxpgmWY99UeMajbQabeWnwbUZEZmM57gFYLmtnc5PtpT510JUZM7zBEZF/iUiaiGSLyCbg/4CHajsuB6Ftx4bC6WVjRCRPRK4Ac4EgY0zpXNVrxphGWEZOzMGSA9A2YzMv2mYsRCS/cGrmLsAz3GR7qU8ddGXGDFeW70ZMbQfhIEqMIV94P8M9aNsprWhUowbTbowxBvgLlhtPR4tIbuGqBt1myshLaQ2uzZTixP/aRaXbS73poCs5ZniDYoy5xRgTbIxpboxxMsZMBAYCf6/t2GpS4bE3BxoDjYvyAewE3I0xowvXLwG+re83+xSxlxdjjL8x5l5jTCNjmdP9bSBKREpfqqvP1gD3AQ+LyI1iyxt0m8FOXhpymzHG3GaMGW+MaW2MaWyMCQYeB77gZtuLiNSbF5bb1z8GMoDzwITajskRXkBHIBrL5ZTrwD+BYbUdVy3kYRn/u7Oy6LWscN1QLDd13ACisDwqUesx12ZeCj9czhT+PV3GMhnO7bUdbw3mxbUwF1lYLlEWvSY25DZTVl4acpsp/Jw9UPgZmwrEATOLra90e9GxuJVSSikHVG8ucSullFL1iXbQSimllAPSDloppZRyQNpBK6WUUg5IO2illFLKAWkHrZRSSjkg7aCVUkopB6QdtFJKKeWAtINWSimlHND/Ax3K0PzJ7zccAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not satisfied with the performance of your model, you should go back and tune the hyperparameters. The first one to check is the learning rate. If that doesn’t help, try another optimizer (and always retune the learning rate after changing any hyperparameter). If the performance is still not great, then try tuning model hyperparameters such as the number of layers, the number of neurons per layer, and the types of activation functions to use for each hidden layer. You can also try tuning other hyperparameters, such as the batch size (it can be set in the fit() method using the batch_size argument, which defaults to 32). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.4 Evaluate the performance of the Test set\n",
    "\n",
    "Once you are satisfied with your model’s validation accuracy, you should evaluate it on the test set to estimate the generalization error before you deploy the model to production. \n",
    "\n",
    "You can easily do this using the evaluate() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64.93289541015625, 0.8488]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_net.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.5 Use the model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We have no new data let's fake it from the test set!\n",
    "X_new = X_test[:4]\n",
    "y_prob = n_net.predict(X_new)\n",
    "y_prob.round(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case you get a probability (0 to 1) for each class for every new instance submitted to the Network. You can directly get the class with highest probability using `predict_classes()` rather than `predict()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = n_net.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has the classifier classified the images correctly? Do check it out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Building Complex Models Using the Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One example of a nonsequential neural network is a _Wide & Deep_ neural network. This neural network architecture was introduced in a 2016 paper by Heng-Tze Cheng et al. It connects all or part of the inputs directly to the output layer. This architecture makes it possible for the neural network to learn both deep patterns (using the deep path) and simple rules (through the short path).17 In contrast, a regular MLP forces all the data to flow through the full stack of layers; thus, simple patterns in the data may end up being distorted by this sequence of transformations.\n",
    "\n",
    "Let’s build such a neural network to tackle the Kings County housing problem. First let's import and preprocess the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's import the KC dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "filepath = os.path.abspath(os.path.join('datasets', 'kings_county_house_data.csv'))\n",
    "housing = pd.read_csv(filepath, dtype={'zipcode': str})\n",
    "housing.drop(\n",
    "    columns=['date', 'id', 'waterfront', 'view', 'yr_built', 'yr_renovated', 'zipcode'],\n",
    "    inplace=True\n",
    ")\n",
    "housing.dtypes\n",
    "X = housing.drop(columns='price')\n",
    "y = housing['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bedrooms  bathrooms  sqft_living  sqft_lot  floors  condition  grade  \\\n",
       "0             3       1.00         1180      5650     1.0          3      7   \n",
       "1             3       2.25         2570      7242     2.0          3      7   \n",
       "2             2       1.00          770     10000     1.0          3      6   \n",
       "3             4       3.00         1960      5000     1.0          5      7   \n",
       "4             3       2.00         1680      8080     1.0          3      8   \n",
       "...         ...        ...          ...       ...     ...        ...    ...   \n",
       "21608         3       2.50         1530      1131     3.0          3      8   \n",
       "21609         4       2.50         2310      5813     2.0          3      8   \n",
       "21610         2       0.75         1020      1350     2.0          3      7   \n",
       "21611         3       2.50         1600      2388     2.0          3      8   \n",
       "21612         2       0.75         1020      1076     2.0          3      7   \n",
       "\n",
       "       sqft_above  sqft_basement      lat     long  sqft_living15  sqft_lot15  \n",
       "0            1180              0  47.5112 -122.257           1340        5650  \n",
       "1            2170            400  47.7210 -122.319           1690        7639  \n",
       "2             770              0  47.7379 -122.233           2720        8062  \n",
       "3            1050            910  47.5208 -122.393           1360        5000  \n",
       "4            1680              0  47.6168 -122.045           1800        7503  \n",
       "...           ...            ...      ...      ...            ...         ...  \n",
       "21608        1530              0  47.6993 -122.346           1530        1509  \n",
       "21609        2310              0  47.5107 -122.362           1830        7200  \n",
       "21610        1020              0  47.5944 -122.299           1020        2007  \n",
       "21611        1600              0  47.5345 -122.069           1410        1287  \n",
       "21612        1020              0  47.5941 -122.299           1020        1357  \n",
       "\n",
       "[21613 rows x 13 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        221900.0\n",
       "1        538000.0\n",
       "2        180000.0\n",
       "3        604000.0\n",
       "4        510000.0\n",
       "           ...   \n",
       "21608    360000.0\n",
       "21609    400000.0\n",
       "21610    402101.0\n",
       "21611    400000.0\n",
       "21612    325000.0\n",
       "Name: price, Length: 21613, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X.values, y.values)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12156, 13), (4053, 13), (5404, 13), (13,))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape, X_train.shape[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's design the Network:\n",
    "\n",
    "- First, we need to create an `Input` object. This is a specification of the kind of input the model will get, including its shape and dtype. A model may actually have multiple inputs, as we will see shortly.\n",
    "\n",
    "- Next, we create a `Dense` layer with 30 neurons, using the ReLU activation function. As soon as it is created, notice that we call it like a function, passing it the input. This is why this is called the Functional API. Note that we are just telling Keras how it should connect the layers together; no actual data is being processed yet.\n",
    "\n",
    "- We then create a second hidden layer, and again we use it as a function. Note that we pass it the output of the first hidden layer.\n",
    "\n",
    "- Next, we create a `Concatenate` layer, and once again we immediately use it like a function, to concatenate the input and the output of the second hidden layer. You may prefer the `keras.layers.concatenate()` function, which creates a `Concatenate` layer and immediately calls it with the given inputs.\n",
    "\n",
    "- Then we create the `output` layer, with a single neuron and no activation function, and we call it like a function, passing it the result of the concatenation.\n",
    "\n",
    "- Lastly, we create a Keras `Model`, specifying which inputs and outputs to use. Have a look at the Keras Model specifications here: https://www.tensorflow.org/api_docs/python/tf/keras/Model\n",
    "\n",
    "Once you have built the Keras model, everything is exactly like earlier, so there’s no need to repeat it here: you must compile the model, train it, evaluate it, and use it to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_0 = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden_0 = keras.layers.Dense(100, activation='relu')(input_0)\n",
    "hidden_1 = keras.layers.Dense(30, activation='relu')(hidden_0)\n",
    "concat = keras.layers.Concatenate()([input_0, hidden_1])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "n_net = keras.Model(inputs=[input_0], outputs=[output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 13)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 100)          1400        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 30)           3030        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 43)           0           input_2[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            44          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 4,474\n",
      "Trainable params: 4,474\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**: Call the `n_net.compile()` method with the appropriate loss function for regression (see your notes), the same metric we used on week 3 to evaluate our regressors (do you remember which one it was?), an SGD optimizer with a reasonable learning rate. Then train the network for 50 epochs, or a smaller number if the algorithm takes too long to go through each epoch, passing both the training and the validation set. When you are happy with your learning rate, then evaluate your model on the test set and print out MSE and RMSE as conputed on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here: compile and train\n",
    "n_net.compile(\n",
    "    loss=keras.losses.mean_squared_error,\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.001),\n",
    "    metrics=[keras.metrics.RootMeanSquaredError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12156 samples, validate on 4053 samples\n",
      "Epoch 1/50\n",
      "12156/12156 [==============================] - 1s 118us/sample - loss: 745197204999071.8750 - root_mean_squared_error: 27298298.0000 - val_loss: 406345478650.3153 - val_root_mean_squared_error: 637452.2500\n",
      "Epoch 2/50\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 235328264393.4979 - root_mean_squared_error: 485106.2812 - val_loss: 132496376200.1165 - val_root_mean_squared_error: 364000.5312\n",
      "Epoch 3/50\n",
      "12156/12156 [==============================] - 1s 70us/sample - loss: 94327991334.7496 - root_mean_squared_error: 307128.5625 - val_loss: 68939596770.4397 - val_root_mean_squared_error: 262563.5312\n",
      "Epoch 4/50\n",
      "12156/12156 [==============================] - 1s 73us/sample - loss: 61044637130.5930 - root_mean_squared_error: 247072.1094 - val_loss: 53735681567.9605 - val_root_mean_squared_error: 231809.6094\n",
      "Epoch 5/50\n",
      "12156/12156 [==============================] - 1s 70us/sample - loss: 52934273669.6018 - root_mean_squared_error: 230074.5000 - val_loss: 49964890750.1999 - val_root_mean_squared_error: 223528.2969\n",
      "Epoch 6/50\n",
      "12156/12156 [==============================] - 1s 90us/sample - loss: 50781034241.2636 - root_mean_squared_error: 225346.4688 - val_loss: 49063574103.7967 - val_root_mean_squared_error: 221503.0156\n",
      "Epoch 7/50\n",
      "12156/12156 [==============================] - 1s 93us/sample - loss: 50248410802.4166 - root_mean_squared_error: 224161.5938 - val_loss: 48749477685.8781 - val_root_mean_squared_error: 220792.8438\n",
      "Epoch 8/50\n",
      "12156/12156 [==============================] - 1s 80us/sample - loss: 50010940863.8105 - root_mean_squared_error: 223631.2812 - val_loss: 48576083938.1870 - val_root_mean_squared_error: 220399.7812\n",
      "Epoch 9/50\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 49946322955.4564 - root_mean_squared_error: 223486.7500 - val_loss: 48538600909.5959 - val_root_mean_squared_error: 220314.7812\n",
      "Epoch 10/50\n",
      "12156/12156 [==============================] - 1s 111us/sample - loss: 49924645545.3188 - root_mean_squared_error: 223438.2344 - val_loss: 48590688924.0128 - val_root_mean_squared_error: 220432.9531\n",
      "Epoch 11/50\n",
      "12156/12156 [==============================] - 1s 110us/sample - loss: 49797821730.7904 - root_mean_squared_error: 223154.2500 - val_loss: 48506287809.1527 - val_root_mean_squared_error: 220241.4219\n",
      "Epoch 12/50\n",
      "12156/12156 [==============================] - 1s 95us/sample - loss: 49851918017.2425 - root_mean_squared_error: 223275.4219 - val_loss: 48590776268.9642 - val_root_mean_squared_error: 220433.1719\n",
      "Epoch 13/50\n",
      "12156/12156 [==============================] - 1s 86us/sample - loss: 49843261875.3432 - root_mean_squared_error: 223256.0469 - val_loss: 48731911082.8562 - val_root_mean_squared_error: 220753.0625\n",
      "Epoch 14/50\n",
      "12156/12156 [==============================] - 1s 78us/sample - loss: 49882907171.8855 - root_mean_squared_error: 223344.8125 - val_loss: 48550298160.8882 - val_root_mean_squared_error: 220341.3281\n",
      "Epoch 15/50\n",
      "12156/12156 [==============================] - 1s 73us/sample - loss: 49777997639.3498 - root_mean_squared_error: 223109.7969 - val_loss: 48786468661.8781 - val_root_mean_squared_error: 220876.6094\n",
      "Epoch 16/50\n",
      "12156/12156 [==============================] - 1s 73us/sample - loss: 49827446398.5258 - root_mean_squared_error: 223220.6250 - val_loss: 48487848991.5815 - val_root_mean_squared_error: 220199.5781\n",
      "Epoch 17/50\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 49843872059.7249 - root_mean_squared_error: 223257.4531 - val_loss: 48567795438.1248 - val_root_mean_squared_error: 220381.0625\n",
      "Epoch 18/50\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 49835284132.2646 - root_mean_squared_error: 223238.2031 - val_loss: 48473573450.2798 - val_root_mean_squared_error: 220167.1875\n",
      "Epoch 19/50\n",
      "12156/12156 [==============================] - 1s 73us/sample - loss: 49846658118.4232 - root_mean_squared_error: 223263.7031 - val_loss: 48486669579.0535 - val_root_mean_squared_error: 220196.9062\n",
      "Epoch 20/50\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 49837549865.1925 - root_mean_squared_error: 223243.2969 - val_loss: 48478113450.4140 - val_root_mean_squared_error: 220177.4375\n",
      "Epoch 21/50\n",
      "12156/12156 [==============================] - 1s 73us/sample - loss: 49830912811.3827 - root_mean_squared_error: 223228.4062 - val_loss: 48461688001.2791 - val_root_mean_squared_error: 220140.1875\n",
      "Epoch 22/50\n",
      "12156/12156 [==============================] - 1s 96us/sample - loss: 49766679730.9220 - root_mean_squared_error: 223084.4375 - val_loss: 48459786182.9006 - val_root_mean_squared_error: 220135.8438\n",
      "Epoch 23/50\n",
      "12156/12156 [==============================] - 1s 96us/sample - loss: 49834833585.7427 - root_mean_squared_error: 223237.1562 - val_loss: 48545523962.1258 - val_root_mean_squared_error: 220330.5000\n",
      "Epoch 24/50\n",
      "12156/12156 [==============================] - 1s 87us/sample - loss: 49842333978.7035 - root_mean_squared_error: 223253.9219 - val_loss: 48437058721.9502 - val_root_mean_squared_error: 220084.1875\n",
      "Epoch 25/50\n",
      "12156/12156 [==============================] - 1s 78us/sample - loss: 49850398910.7154 - root_mean_squared_error: 223272.0312 - val_loss: 48482002556.4313 - val_root_mean_squared_error: 220186.2812\n",
      "Epoch 26/50\n",
      "12156/12156 [==============================] - 1s 73us/sample - loss: 49850510420.5752 - root_mean_squared_error: 223272.2969 - val_loss: 48486344508.4471 - val_root_mean_squared_error: 220196.1719\n",
      "Epoch 27/50\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 49835233363.5643 - root_mean_squared_error: 223238.1094 - val_loss: 48571960205.0432 - val_root_mean_squared_error: 220390.4688\n",
      "Epoch 28/50\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 49852813533.0411 - root_mean_squared_error: 223277.4375 - val_loss: 48479844213.0412 - val_root_mean_squared_error: 220181.4062\n",
      "Epoch 29/50\n",
      "12156/12156 [==============================] - 1s 73us/sample - loss: 49831231474.5219 - root_mean_squared_error: 223229.0938 - val_loss: 48450664102.8769 - val_root_mean_squared_error: 220115.0938\n",
      "Epoch 30/50\n",
      "12156/12156 [==============================] - 1s 70us/sample - loss: 49843123795.3959 - root_mean_squared_error: 223255.7188 - val_loss: 48458831759.3171 - val_root_mean_squared_error: 220133.6406\n",
      "Epoch 31/50\n",
      "12156/12156 [==============================] - 1s 74us/sample - loss: 49872765541.2544 - root_mean_squared_error: 223322.0938 - val_loss: 48449178215.9664 - val_root_mean_squared_error: 220111.7188\n",
      "Epoch 32/50\n",
      "12156/12156 [==============================] - 1s 76us/sample - loss: 49825468343.2182 - root_mean_squared_error: 223216.2344 - val_loss: 48472851324.3681 - val_root_mean_squared_error: 220165.4531\n",
      "Epoch 33/50\n",
      "12156/12156 [==============================] - 1s 75us/sample - loss: 49819557307.7670 - root_mean_squared_error: 223203.0312 - val_loss: 48428976584.2902 - val_root_mean_squared_error: 220065.8750\n",
      "Epoch 34/50\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 49839801630.7470 - root_mean_squared_error: 223248.3438 - val_loss: 48461734633.8298 - val_root_mean_squared_error: 220140.2344\n",
      "Epoch 35/50\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 49787956856.4607 - root_mean_squared_error: 223132.1406 - val_loss: 48466120995.0555 - val_root_mean_squared_error: 220150.2188\n",
      "Epoch 36/50\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 49832309329.3741 - root_mean_squared_error: 223231.5000 - val_loss: 48465755542.5176 - val_root_mean_squared_error: 220149.4219\n",
      "Epoch 37/50\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 49841735882.8457 - root_mean_squared_error: 223252.6719 - val_loss: 48593813598.9973 - val_root_mean_squared_error: 220440.0781\n",
      "Epoch 38/50\n",
      "12156/12156 [==============================] - 1s 82us/sample - loss: 49811534026.8457 - root_mean_squared_error: 223185.0000 - val_loss: 48444163359.7710 - val_root_mean_squared_error: 220100.3594\n",
      "Epoch 39/50\n",
      "12156/12156 [==============================] - 1s 97us/sample - loss: 49793363437.9730 - root_mean_squared_error: 223144.2812 - val_loss: 48438913326.6775 - val_root_mean_squared_error: 220088.4219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "12156/12156 [==============================] - 1s 116us/sample - loss: 49801786528.7266 - root_mean_squared_error: 223163.1250 - val_loss: 48463555049.6403 - val_root_mean_squared_error: 220144.4062\n",
      "Epoch 41/50\n",
      "12156/12156 [==============================] - 1s 80us/sample - loss: 49859292628.7015 - root_mean_squared_error: 223291.9844 - val_loss: 48442630396.6524 - val_root_mean_squared_error: 220096.8438\n",
      "Epoch 42/50\n",
      "12156/12156 [==============================] - 1s 73us/sample - loss: 49801515470.9733 - root_mean_squared_error: 223162.5469 - val_loss: 48548508572.7076 - val_root_mean_squared_error: 220337.2500\n",
      "Epoch 43/50\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 49799199614.2731 - root_mean_squared_error: 223157.3281 - val_loss: 48436023851.8352 - val_root_mean_squared_error: 220081.8594\n",
      "Epoch 44/50\n",
      "12156/12156 [==============================] - 1s 73us/sample - loss: 49835151398.4126 - root_mean_squared_error: 223237.8906 - val_loss: 48420849054.0972 - val_root_mean_squared_error: 220047.3594\n",
      "Epoch 45/50\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 49846173333.4386 - root_mean_squared_error: 223262.5625 - val_loss: 48430177918.9578 - val_root_mean_squared_error: 220068.5938\n",
      "Epoch 46/50\n",
      "12156/12156 [==============================] - 1s 74us/sample - loss: 49837043373.6992 - root_mean_squared_error: 223242.1406 - val_loss: 48430358488.5862 - val_root_mean_squared_error: 220069.0000\n",
      "Epoch 47/50\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 49805600811.8039 - root_mean_squared_error: 223171.7188 - val_loss: 48456078342.8216 - val_root_mean_squared_error: 220127.4219\n",
      "Epoch 48/50\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 49816147899.9355 - root_mean_squared_error: 223195.3438 - val_loss: 48509441623.0387 - val_root_mean_squared_error: 220248.5781\n",
      "Epoch 49/50\n",
      "12156/12156 [==============================] - 1s 69us/sample - loss: 49840485550.2047 - root_mean_squared_error: 223249.8281 - val_loss: 48550088716.1273 - val_root_mean_squared_error: 220340.8281\n",
      "Epoch 50/50\n",
      "12156/12156 [==============================] - 1s 69us/sample - loss: 49851534616.6818 - root_mean_squared_error: 223274.6250 - val_loss: 48543297191.3822 - val_root_mean_squared_error: 220325.4219\n"
     ]
    }
   ],
   "source": [
    "history = n_net.fit(\n",
    "    X_train, y_train, epochs=50, validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you see happening? If you notice somthing amiss, try some bounded activation function (i.e. sigmoid or tanh). Other option could be different data scaling techniques such as quantile scaling (https://en.wikipedia.org/wiki/Quantile_normalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here: test set evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the RMSE of this Neural Network compares to the one we obtained from the Regression algorithms we tried in Week 3?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Using the Subclassing API to Build Dynamic Models\n",
    "\n",
    "Both the two APIs we have seen so far, the Sequential and the Functional, are declarative. This means that you declare which layers you are going to use and how they will be connected. Afterwards, you can start to feed the model some data for training or inference. There are a few advantages in this approach: \n",
    "* the model can easily be saved, cloned, and shared; \n",
    "* its structure can be displayed and analysed; \n",
    "* the framework can infer shapes and check types, so errors can be caught early. \n",
    "* It’s also fairly easy to debug, given that the whole model is a static graph of layers. \n",
    "\n",
    "However, the main disadvantage is just that the model is static. Some networks involve loops, varying shapes, conditional branching, and other dynamic behaviors. For these cases, or just if you favour a more imperative programming style, you can use the Subclassing API\n",
    "\n",
    "What you have to do is: subclass the Model class, create the layers you need in the constructor, and use them to perform the computations you want in a `call()` method. \n",
    "\n",
    "Let's see how we can do it with the \"Wide & Deep\" model we have seen in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepNetwork(keras.models.Model):\n",
    "    \n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs) # handles standard args, such as 'name'\n",
    "        self.hidden_0 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden_1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.output_0 = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        hidden_0 = self.hidden_0(inputs)\n",
    "        hidden_1 = self.hidden_1(hidden_0)\n",
    "        concat = keras.layers.concatenate([inputs, hidden_1])\n",
    "        return self.output_0(concat)\n",
    "    \n",
    "n_net = WideAndDeepNetwork(30, activation='tanh')\n",
    "n_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example looks very much like the Functional API, except we do not need to create the inputs; we just use the input argument to the call() method, and we separate the creation of the layers21 in the constructor from their usage in the call() method. The big difference is that you can do pretty much anything you want in the call() method: for loops, if statements, low-level TensorFlow operations—your imagination is the limit! This makes it a great API for researchers experimenting with new ideas.\n",
    "\n",
    "This extra flexibility does come at a cost: your model’s architecture is hidden within the call() method, so Keras cannot easily inspect it; it cannot save or clone it; and when you call the summary() method, you only get a list of layers, without any information on how they are connected to each other. Moreover, Keras cannot check types and shapes ahead of time, and it is easier to make mistakes. So unless you really need that extra flexibility, you should probably stick to the Sequential API or the Functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_net.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "    metrics=[keras.metrics.RootMeanSquaredError()]\n",
    ")\n",
    "history = n_net.fit(\n",
    "    X_train, y_train, epochs=30,\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n",
    "mse, rmse = n_net.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Using TensorBoard for Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard is an interactive tool, shipped together with TensorFlow, that helps to visualise and comprare the training performance of your network.\n",
    "\n",
    "Before we can use it, we need to modify our code to output log files that are named \"event files\". TensorBoard will pick up these files as soon as they are created and visualise them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2020_03_04-20_28_25'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to be done\n",
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    \"\"\"\n",
    "    This method will generate a different directory with name based on creation timestamp\n",
    "    every time we run the code\n",
    "    \"\"\"\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir() \n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here rather than using SGD optimiser and tanh as activation function, we are going to use a more up-to-date approach to avoid the issue of vanishing exploding/gradients: we will use the SeLU activation function and the improved \"Adam\" optimisation algorithm (see Notebook 06B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_net = keras.models.Sequential([\n",
    "    keras.layers.Dense(\n",
    "        100, activation=\"selu\", kernel_initializer='lecun_normal', input_shape=[13]\n",
    "    ),\n",
    "    keras.layers.Dense(\n",
    "        30, activation=\"selu\", kernel_initializer='lecun_normal'\n",
    "    ),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "n_net.compile(\n",
    "    loss=\"mse\", \n",
    "    optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "    metrics=[keras.metrics.RootMeanSquaredError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_1 = n_net.get_layer('dense_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.keras.activations.selu(x)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_1.activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               1400      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                3030      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 4,461\n",
      "Trainable params: 4,461\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Keras's `TensorBoard()` callbacks to create a log directory and the event files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12156 samples, validate on 4053 samples\n",
      "Epoch 1/40\n",
      "12156/12156 [==============================] - 2s 195us/sample - loss: 424211933155.0221 - root_mean_squared_error: 651315.4375 - val_loss: 431933768880.6040 - val_root_mean_squared_error: 657216.6250\n",
      "Epoch 2/40\n",
      "12156/12156 [==============================] - 1s 88us/sample - loss: 420364881878.2178 - root_mean_squared_error: 648355.5000 - val_loss: 424206949068.0168 - val_root_mean_squared_error: 651311.6250\n",
      "Epoch 3/40\n",
      "12156/12156 [==============================] - 1s 89us/sample - loss: 408377598418.3429 - root_mean_squared_error: 639044.3125 - val_loss: 406567257858.8423 - val_root_mean_squared_error: 637626.2500\n",
      "Epoch 4/40\n",
      "12156/12156 [==============================] - 1s 89us/sample - loss: 386248471831.3340 - root_mean_squared_error: 621488.8750 - val_loss: 377811685480.0928 - val_root_mean_squared_error: 614663.9375\n",
      "Epoch 5/40\n",
      "12156/12156 [==============================] - 1s 88us/sample - loss: 354535355913.9401 - root_mean_squared_error: 595428.8125 - val_loss: 340496445056.9790 - val_root_mean_squared_error: 583520.8125\n",
      "Epoch 6/40\n",
      "12156/12156 [==============================] - 1s 88us/sample - loss: 315760247932.3356 - root_mean_squared_error: 561925.5625 - val_loss: 297344621979.5707 - val_root_mean_squared_error: 545293.1875\n",
      "Epoch 7/40\n",
      "12156/12156 [==============================] - 1s 87us/sample - loss: 273716329584.8792 - root_mean_squared_error: 523179.0938 - val_loss: 253146450867.4464 - val_root_mean_squared_error: 503136.6562\n",
      "Epoch 8/40\n",
      "12156/12156 [==============================] - 1s 88us/sample - loss: 233564143939.4749 - root_mean_squared_error: 483284.8438 - val_loss: 213617379717.5899 - val_root_mean_squared_error: 462187.6250\n",
      "Epoch 9/40\n",
      "12156/12156 [==============================] - 1s 87us/sample - loss: 198921233184.6002 - root_mean_squared_error: 446005.9062 - val_loss: 181202300427.7483 - val_root_mean_squared_error: 425678.6562\n",
      "Epoch 10/40\n",
      "12156/12156 [==============================] - 1s 88us/sample - loss: 171885368968.6344 - root_mean_squared_error: 414590.6875 - val_loss: 157706892087.6467 - val_root_mean_squared_error: 397123.2500\n",
      "Epoch 11/40\n",
      "12156/12156 [==============================] - 1s 90us/sample - loss: 153039754856.2869 - root_mean_squared_error: 391202.8750 - val_loss: 142058272754.3568 - val_root_mean_squared_error: 376906.0938\n",
      "Epoch 12/40\n",
      "12156/12156 [==============================] - 1s 88us/sample - loss: 140550281660.1040 - root_mean_squared_error: 374900.3750 - val_loss: 131830696368.0355 - val_root_mean_squared_error: 363084.9375\n",
      "Epoch 13/40\n",
      "12156/12156 [==============================] - 1s 88us/sample - loss: 132080043736.1553 - root_mean_squared_error: 363428.1875 - val_loss: 124726083195.9260 - val_root_mean_squared_error: 353165.8125\n",
      "Epoch 14/40\n",
      "12156/12156 [==============================] - 1s 100us/sample - loss: 125716357157.7387 - root_mean_squared_error: 354565.0625 - val_loss: 119177481721.5574 - val_root_mean_squared_error: 345220.9375\n",
      "Epoch 15/40\n",
      "12156/12156 [==============================] - 1s 119us/sample - loss: 120354762211.5275 - root_mean_squared_error: 346921.8438 - val_loss: 114285190135.1572 - val_root_mean_squared_error: 338060.9375\n",
      "Epoch 16/40\n",
      "12156/12156 [==============================] - 1s 110us/sample - loss: 115556921647.2577 - root_mean_squared_error: 339936.6250 - val_loss: 109857752978.3489 - val_root_mean_squared_error: 331448.0000\n",
      "Epoch 17/40\n",
      "12156/12156 [==============================] - 1s 89us/sample - loss: 111211110090.0033 - root_mean_squared_error: 333483.2812 - val_loss: 105850252138.6825 - val_root_mean_squared_error: 325346.3438\n",
      "Epoch 18/40\n",
      "12156/12156 [==============================] - 1s 93us/sample - loss: 107350024914.4271 - root_mean_squared_error: 327643.2188 - val_loss: 102325285134.8433 - val_root_mean_squared_error: 319883.2500\n",
      "Epoch 19/40\n",
      "12156/12156 [==============================] - 1s 108us/sample - loss: 103989651278.7627 - root_mean_squared_error: 322474.3438 - val_loss: 99293720331.4325 - val_root_mean_squared_error: 315109.0938\n",
      "Epoch 20/40\n",
      "12156/12156 [==============================] - 1s 89us/sample - loss: 101133453703.5393 - root_mean_squared_error: 318014.8438 - val_loss: 96773180427.3694 - val_root_mean_squared_error: 311083.8438\n",
      "Epoch 21/40\n",
      "12156/12156 [==============================] - 1s 93us/sample - loss: 98765005910.5969 - root_mean_squared_error: 314269.0312 - val_loss: 94714654049.9660 - val_root_mean_squared_error: 307757.4375\n",
      "Epoch 22/40\n",
      "12156/12156 [==============================] - 1s 95us/sample - loss: 96851456047.1734 - root_mean_squared_error: 311209.7188 - val_loss: 93079419309.0037 - val_root_mean_squared_error: 305089.1875\n",
      "Epoch 23/40\n",
      "12156/12156 [==============================] - 1s 93us/sample - loss: 95330234113.2636 - root_mean_squared_error: 308755.9375 - val_loss: 91769889333.9413 - val_root_mean_squared_error: 302935.4688\n",
      "Epoch 24/40\n",
      "12156/12156 [==============================] - 1s 91us/sample - loss: 94067752073.1399 - root_mean_squared_error: 306704.6875 - val_loss: 90673732672.9317 - val_root_mean_squared_error: 301120.7812\n",
      "Epoch 25/40\n",
      "12156/12156 [==============================] - 1s 89us/sample - loss: 93029172113.8164 - root_mean_squared_error: 305006.8438 - val_loss: 89737557685.0254 - val_root_mean_squared_error: 299562.2812\n",
      "Epoch 26/40\n",
      "12156/12156 [==============================] - 1s 88us/sample - loss: 92121851229.4202 - root_mean_squared_error: 303515.7500 - val_loss: 88878532730.7890 - val_root_mean_squared_error: 298125.0312\n",
      "Epoch 27/40\n",
      "12156/12156 [==============================] - 1s 90us/sample - loss: 91285514769.0161 - root_mean_squared_error: 302135.0000 - val_loss: 88058531012.3109 - val_root_mean_squared_error: 296746.5625\n",
      "Epoch 28/40\n",
      "12156/12156 [==============================] - 1s 105us/sample - loss: 90476483483.2511 - root_mean_squared_error: 300793.0625 - val_loss: 87263049644.6247 - val_root_mean_squared_error: 295403.2188\n",
      "Epoch 29/40\n",
      "12156/12156 [==============================] - 1s 115us/sample - loss: 89664297598.1889 - root_mean_squared_error: 299440.0000 - val_loss: 86430884608.0632 - val_root_mean_squared_error: 293991.3125\n",
      "Epoch 30/40\n",
      "12156/12156 [==============================] - 1s 98us/sample - loss: 88850853905.5216 - root_mean_squared_error: 298078.6250 - val_loss: 85595329046.6124 - val_root_mean_squared_error: 292566.8438\n",
      "Epoch 31/40\n",
      "12156/12156 [==============================] - 1s 89us/sample - loss: 88013428832.3685 - root_mean_squared_error: 296670.6250 - val_loss: 84749013476.0819 - val_root_mean_squared_error: 291116.8438\n",
      "Epoch 32/40\n",
      "12156/12156 [==============================] - 1s 93us/sample - loss: 87154101548.2251 - root_mean_squared_error: 295218.8125 - val_loss: 83881028996.3267 - val_root_mean_squared_error: 289622.2500\n",
      "Epoch 33/40\n",
      "12156/12156 [==============================] - 1s 93us/sample - loss: 86226041657.5347 - root_mean_squared_error: 293642.6250 - val_loss: 82938281884.9603 - val_root_mean_squared_error: 287990.0312\n",
      "Epoch 34/40\n",
      "12156/12156 [==============================] - 1s 88us/sample - loss: 85162067995.6301 - root_mean_squared_error: 291825.4375 - val_loss: 81668116146.4989 - val_root_mean_squared_error: 285776.3125\n",
      "Epoch 35/40\n",
      "12156/12156 [==============================] - 1s 88us/sample - loss: 83794306235.6828 - root_mean_squared_error: 289472.4688 - val_loss: 80345468707.6871 - val_root_mean_squared_error: 283452.7188\n",
      "Epoch 36/40\n",
      "12156/12156 [==============================] - 1s 87us/sample - loss: 82349423382.4916 - root_mean_squared_error: 286965.8750 - val_loss: 78909238247.9980 - val_root_mean_squared_error: 280907.8438\n",
      "Epoch 37/40\n",
      "12156/12156 [==============================] - 1s 92us/sample - loss: 80785717290.4561 - root_mean_squared_error: 284228.2500 - val_loss: 77353164781.8090 - val_root_mean_squared_error: 278124.3750\n",
      "Epoch 38/40\n",
      "12156/12156 [==============================] - 1s 102us/sample - loss: 79049648895.5788 - root_mean_squared_error: 281157.7812 - val_loss: 75697345924.8320 - val_root_mean_squared_error: 275131.5000\n",
      "Epoch 39/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12156/12156 [==============================] - 1s 116us/sample - loss: 77177283808.0737 - root_mean_squared_error: 277807.9688 - val_loss: 73840119388.5971 - val_root_mean_squared_error: 271735.4062\n",
      "Epoch 40/40\n",
      "12156/12156 [==============================] - 1s 117us/sample - loss: 75129507554.2639 - root_mean_squared_error: 274097.5625 - val_loss: 71832760492.8142 - val_root_mean_squared_error: 268016.3438\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = n_net.fit(X_train, y_train, epochs=40, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorboard  # or %reload_ext tensorboard'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-67-25ad531d5905>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'load_ext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tensorboard  # or %reload_ext tensorboard'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tensorboard'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'--logdir=./my_logs --port=6007'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda3\\envs\\P4DS\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2315\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2316\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2317\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2318\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<C:\\Python\\Anaconda3\\envs\\P4DS\\lib\\site-packages\\decorator.py:decorator-gen-65>\u001b[0m in \u001b[0;36mload_ext\u001b[1;34m(self, module_str)\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda3\\envs\\P4DS\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda3\\envs\\P4DS\\lib\\site-packages\\IPython\\core\\magics\\extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Missing module name.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'already loaded'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda3\\envs\\P4DS\\lib\\site-packages\\IPython\\core\\extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                     \u001b[0mmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                         print((\"Loading extensions from {dir} is deprecated. \"\n",
      "\u001b[1;32mC:\\Python\\Anaconda3\\envs\\P4DS\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda3\\envs\\P4DS\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda3\\envs\\P4DS\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32mC:\\Python\\Anaconda3\\envs\\P4DS\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard  # or %reload_ext tensorboard'"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard  # or %reload_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python\\Anaconda3\\envs\\P4DS\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Python\\Anaconda3\\envs\\P4DS\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Python\\Anaconda3\\envs\\P4DS\\lib\\site-packages\\tensorboard\\main.py\", line 79, in <module>\n",
      "    run_main()\n",
      "  File \"C:\\Python\\Anaconda3\\envs\\P4DS\\lib\\site-packages\\tensorboard\\main.py\", line 66, in run_main\n",
      "    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n",
      "  File \"C:\\Python\\Anaconda3\\envs\\P4DS\\lib\\site-packages\\absl\\app.py\", line 299, in run\n",
      "    _run_main(main, args)\n",
      "  File \"C:\\Python\\Anaconda3\\envs\\P4DS\\lib\\site-packages\\absl\\app.py\", line 250, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"C:\\Python\\Anaconda3\\envs\\P4DS\\lib\\site-packages\\tensorboard\\program.py\", line 268, in main\n",
      "    return runner(self.flags) or 0\n",
      "  File \"C:\\Python\\Anaconda3\\envs\\P4DS\\lib\\site-packages\\tensorboard\\program.py\", line 282, in _run_serve_subcommand\n",
      "    server = self._make_server()\n",
      "  File \"C:\\Python\\Anaconda3\\envs\\P4DS\\lib\\site-packages\\tensorboard\\program.py\", line 362, in _make_server\n",
      "    return self.server_class(app, self.flags)\n",
      "  File \"C:\\Python\\Anaconda3\\envs\\P4DS\\lib\\site-packages\\tensorboard\\program.py\", line 513, in init\n",
      "    return cls(wsgi_app=wsgi_app, flags=subflags)\n",
      "  File \"C:\\Python\\Anaconda3\\envs\\P4DS\\lib\\site-packages\\tensorboard\\program.py\", line 549, in __init__\n",
      "    super(WerkzeugServer, self).__init__(host, port, wsgi_app)\n",
      "  File \"C:\\Python\\Anaconda3\\envs\\P4DS\\lib\\site-packages\\werkzeug\\serving.py\", line 577, in __init__\n",
      "    self.address_family), handler)\n",
      "  File \"C:\\Python\\Anaconda3\\envs\\P4DS\\lib\\socketserver.py\", line 452, in __init__\n",
      "    self.server_bind()\n",
      "  File \"C:\\Python\\Anaconda3\\envs\\P4DS\\lib\\site-packages\\tensorboard\\program.py\", line 624, in server_bind\n",
      "    super(WerkzeugServer, self).server_bind()\n",
      "  File \"C:\\Python\\Anaconda3\\envs\\P4DS\\lib\\http\\server.py\", line 137, in server_bind\n",
      "    socketserver.TCPServer.server_bind(self)\n",
      "  File \"C:\\Python\\Anaconda3\\envs\\P4DS\\lib\\socketserver.py\", line 466, in server_bind\n",
      "    self.socket.bind(self.server_address)\n",
      "OSError: [WinError 10013] An attempt was made to access a socket in a way forbidden by its access permissions\n"
     ]
    }
   ],
   "source": [
    "!python -m tensorboard.main --logdir=./my_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Fine-Tuning Neural Network Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we had the same issue with other machine learning algorithms, neural networks have many hyperparamenters, even more so. (1) You can use any possible architecture you can conceive, (2) you can tweak the number of layers and (3) the number of neural units per layer, (4) the activation nonlinear function in each layer, and more...\n",
    "\n",
    "A possibility to explore the parameter space is to wrap our Keras model in an object with the same interface as a typical Scikit-Learn regressor or classifier\n",
    "\n",
    "To do so, we can define a function that builds and compiles a Keras network, given a set of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(n_hidden=1, n_neurons=100, activation=\"selu\", \n",
    "                  learning_rate=5e-3, input_shape=[13], kernel_initializer='lecun_normal'):\n",
    "    n_net = keras.models.Sequential()\n",
    "    n_net.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        n_net.add(keras.layers.Dense(\n",
    "            n_neurons, \n",
    "            activation=activation, \n",
    "            kernel_initializer=kernel_initializer\n",
    "        ))\n",
    "    n_net.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
    "    n_net.compile(\n",
    "        loss=keras.losses.mean_squared_error,\n",
    "        optimizer=optimizer,\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "    return n_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12156 samples, validate on 4053 samples\n",
      "Epoch 1/100\n",
      "12156/12156 [==============================] - 2s 160us/sample - loss: 423856712519.0128 - root_mean_squared_error: 651042.8750 - val_loss: 430944545939.8016 - val_root_mean_squared_error: 656463.6250\n",
      "Epoch 2/100\n",
      "12156/12156 [==============================] - 1s 88us/sample - loss: 419335104164.9384 - root_mean_squared_error: 647560.8125 - val_loss: 423756890532.4135 - val_root_mean_squared_error: 650966.2500\n",
      "Epoch 3/100\n",
      "12156/12156 [==============================] - 1s 70us/sample - loss: 410490432607.3577 - root_mean_squared_error: 640695.1250 - val_loss: 412618154236.6523 - val_root_mean_squared_error: 642353.6250\n",
      "Epoch 4/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 398319308963.0852 - root_mean_squared_error: 631125.3125 - val_loss: 398295934753.1606 - val_root_mean_squared_error: 631106.8750\n",
      "Epoch 5/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 383639100526.1836 - root_mean_squared_error: 619386.1875 - val_loss: 381909268870.6005 - val_root_mean_squared_error: 617987.9375\n",
      "Epoch 6/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 367136933468.1566 - root_mean_squared_error: 605918.3125 - val_loss: 363793082092.6089 - val_root_mean_squared_error: 603152.6250\n",
      "Epoch 7/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 349294414838.2284 - root_mean_squared_error: 591011.5000 - val_loss: 344514277053.6156 - val_root_mean_squared_error: 586953.4375\n",
      "Epoch 8/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 330857895016.1185 - root_mean_squared_error: 575202.5000 - val_loss: 325020911977.2928 - val_root_mean_squared_error: 570106.1250\n",
      "Epoch 9/100\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 312157202710.3231 - root_mean_squared_error: 558710.3750 - val_loss: 305299918988.4747 - val_root_mean_squared_error: 552539.3750\n",
      "Epoch 10/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 293453986600.0132 - root_mean_squared_error: 541713.9375 - val_loss: 285946710761.3245 - val_root_mean_squared_error: 534739.8750\n",
      "Epoch 11/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 275247266427.4933 - root_mean_squared_error: 524640.3125 - val_loss: 267154286361.0757 - val_root_mean_squared_error: 516869.7188\n",
      "Epoch 12/100\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 257788629996.1198 - root_mean_squared_error: 507728.8438 - val_loss: 249253699282.8384 - val_root_mean_squared_error: 499253.1562\n",
      "Epoch 13/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 241338979464.4659 - root_mean_squared_error: 491262.6875 - val_loss: 232476613267.4226 - val_root_mean_squared_error: 482158.2812\n",
      "Epoch 14/100\n",
      "12156/12156 [==============================] - 1s 70us/sample - loss: 226133639529.2136 - root_mean_squared_error: 475535.1250 - val_loss: 217310288434.4041 - val_root_mean_squared_error: 466165.5000\n",
      "Epoch 15/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 212331023064.4923 - root_mean_squared_error: 460793.9062 - val_loss: 203546349130.4061 - val_root_mean_squared_error: 451161.0938\n",
      "Epoch 16/100\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 199977021055.8737 - root_mean_squared_error: 447187.8750 - val_loss: 191438269696.9474 - val_root_mean_squared_error: 437536.5938\n",
      "Epoch 17/100\n",
      "12156/12156 [==============================] - 1s 74us/sample - loss: 189114604255.2313 - root_mean_squared_error: 434873.2188 - val_loss: 180870111145.0876 - val_root_mean_squared_error: 425288.1875\n",
      "Epoch 18/100\n",
      "12156/12156 [==============================] - 1s 103us/sample - loss: 179754094507.0879 - root_mean_squared_error: 423974.1562 - val_loss: 171931328186.5838 - val_root_mean_squared_error: 414645.9688\n",
      "Epoch 19/100\n",
      "12156/12156 [==============================] - 1s 94us/sample - loss: 171906033238.7654 - root_mean_squared_error: 414615.5000 - val_loss: 164499683520.5211 - val_root_mean_squared_error: 405585.5938\n",
      "Epoch 20/100\n",
      "12156/12156 [==============================] - 1s 79us/sample - loss: 165302788616.2553 - root_mean_squared_error: 406574.4375 - val_loss: 158323222347.6062 - val_root_mean_squared_error: 397898.5000\n",
      "Epoch 21/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 159784068772.9385 - root_mean_squared_error: 399729.9688 - val_loss: 153204846126.1091 - val_root_mean_squared_error: 391413.9375\n",
      "Epoch 22/100\n",
      "12156/12156 [==============================] - 1s 73us/sample - loss: 155211524126.3257 - root_mean_squared_error: 393968.9688 - val_loss: 148971390045.7340 - val_root_mean_squared_error: 385968.0625\n",
      "Epoch 23/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 151392206050.0954 - root_mean_squared_error: 389091.4688 - val_loss: 145469788272.1776 - val_root_mean_squared_error: 381405.0312\n",
      "Epoch 24/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 148142223213.0885 - root_mean_squared_error: 384892.5000 - val_loss: 142485610655.6763 - val_root_mean_squared_error: 377472.6562\n",
      "Epoch 25/100\n",
      "12156/12156 [==============================] - 1s 73us/sample - loss: 145358711579.8829 - root_mean_squared_error: 381259.4375 - val_loss: 139941708018.5463 - val_root_mean_squared_error: 374087.7812\n",
      "Epoch 26/100\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 142903232757.9756 - root_mean_squared_error: 378025.5312 - val_loss: 137665354771.4542 - val_root_mean_squared_error: 371032.8125\n",
      "Epoch 27/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 140636277642.4034 - root_mean_squared_error: 375015.0625 - val_loss: 135529946673.1409 - val_root_mean_squared_error: 368143.9375\n",
      "Epoch 28/100\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 138478681740.0039 - root_mean_squared_error: 372127.1875 - val_loss: 133505987553.4291 - val_root_mean_squared_error: 365384.7500\n",
      "Epoch 29/100\n",
      "12156/12156 [==============================] - 1s 74us/sample - loss: 136393650223.1734 - root_mean_squared_error: 369315.0938 - val_loss: 131564280604.8655 - val_root_mean_squared_error: 362717.9062\n",
      "Epoch 30/100\n",
      "12156/12156 [==============================] - 1s 73us/sample - loss: 134259919177.5400 - root_mean_squared_error: 366415.0312 - val_loss: 129384203038.3814 - val_root_mean_squared_error: 359700.1250\n",
      "Epoch 31/100\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 131951787417.3978 - root_mean_squared_error: 363251.6875 - val_loss: 127294459527.0427 - val_root_mean_squared_error: 356783.4688\n",
      "Epoch 32/100\n",
      "12156/12156 [==============================] - 1s 73us/sample - loss: 129832634689.4531 - root_mean_squared_error: 360322.9688 - val_loss: 125373764797.7419 - val_root_mean_squared_error: 354081.5625\n",
      "Epoch 33/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 127793568953.6611 - root_mean_squared_error: 357482.2500 - val_loss: 123482375459.8135 - val_root_mean_squared_error: 351400.5938\n",
      "Epoch 34/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 125795078317.8677 - root_mean_squared_error: 354675.9062 - val_loss: 121615428539.5312 - val_root_mean_squared_error: 348734.0312\n",
      "Epoch 35/100\n",
      "12156/12156 [==============================] - 1s 92us/sample - loss: 123813845775.7525 - root_mean_squared_error: 351871.9062 - val_loss: 119775590681.4547 - val_root_mean_squared_error: 346086.1562\n",
      "Epoch 36/100\n",
      "12156/12156 [==============================] - 1s 95us/sample - loss: 121834124184.5554 - root_mean_squared_error: 349047.5625 - val_loss: 117944871736.1520 - val_root_mean_squared_error: 343431.0000\n",
      "Epoch 37/100\n",
      "12156/12156 [==============================] - 1s 84us/sample - loss: 119874587312.0579 - root_mean_squared_error: 346229.0625 - val_loss: 116158544272.7066 - val_root_mean_squared_error: 340820.3750\n",
      "Epoch 38/100\n",
      "12156/12156 [==============================] - 1s 74us/sample - loss: 117940150732.9516 - root_mean_squared_error: 343424.1562 - val_loss: 114395075403.8589 - val_root_mean_squared_error: 338223.4375\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12156/12156 [==============================] - 1s 76us/sample - loss: 116049446759.0234 - root_mean_squared_error: 340660.3750 - val_loss: 112688210964.9701 - val_root_mean_squared_error: 335690.6250\n",
      "Epoch 40/100\n",
      "12156/12156 [==============================] - 1s 78us/sample - loss: 114205711998.5258 - root_mean_squared_error: 337943.3438 - val_loss: 111009415608.6257 - val_root_mean_squared_error: 333180.7812\n",
      "Epoch 41/100\n",
      "12156/12156 [==============================] - 1s 76us/sample - loss: 112404466276.5805 - root_mean_squared_error: 335267.7500 - val_loss: 109367351957.4439 - val_root_mean_squared_error: 330707.3750\n",
      "Epoch 42/100\n",
      "12156/12156 [==============================] - 1s 77us/sample - loss: 110651274104.2080 - root_mean_squared_error: 332642.8438 - val_loss: 107741599132.0760 - val_root_mean_squared_error: 328240.1875\n",
      "Epoch 43/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 108930720512.2527 - root_mean_squared_error: 330046.5312 - val_loss: 106125611585.0580 - val_root_mean_squared_error: 325769.2500\n",
      "Epoch 44/100\n",
      "12156/12156 [==============================] - 1s 73us/sample - loss: 107229394964.8911 - root_mean_squared_error: 327459.0000 - val_loss: 104509546582.9124 - val_root_mean_squared_error: 323279.3750\n",
      "Epoch 45/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 105533690156.5620 - root_mean_squared_error: 324859.5625 - val_loss: 102916791000.1441 - val_root_mean_squared_error: 320806.5312\n",
      "Epoch 46/100\n",
      "12156/12156 [==============================] - 1s 70us/sample - loss: 103860271418.7141 - root_mean_squared_error: 322273.5938 - val_loss: 101294159033.6995 - val_root_mean_squared_error: 318267.4375\n",
      "Epoch 47/100\n",
      "12156/12156 [==============================] - 1s 70us/sample - loss: 102162969272.8187 - root_mean_squared_error: 319629.3750 - val_loss: 99644834260.9228 - val_root_mean_squared_error: 315665.6875\n",
      "Epoch 48/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 100460436830.0941 - root_mean_squared_error: 316954.9688 - val_loss: 98005925261.4221 - val_root_mean_squared_error: 313059.0000\n",
      "Epoch 49/100\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 98762799420.0619 - root_mean_squared_error: 314265.3750 - val_loss: 96349940869.6531 - val_root_mean_squared_error: 310402.8438\n",
      "Epoch 50/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 97054148535.8921 - root_mean_squared_error: 311535.0938 - val_loss: 94689948370.5857 - val_root_mean_squared_error: 307717.3125\n",
      "Epoch 51/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 95337103901.8203 - root_mean_squared_error: 308767.0312 - val_loss: 93005581445.6531 - val_root_mean_squared_error: 304968.1250\n",
      "Epoch 52/100\n",
      "12156/12156 [==============================] - 1s 86us/sample - loss: 93595104667.4195 - root_mean_squared_error: 305933.0938 - val_loss: 91315439868.1470 - val_root_mean_squared_error: 302184.4375\n",
      "Epoch 53/100\n",
      "12156/12156 [==============================] - 1s 90us/sample - loss: 91839801681.6268 - root_mean_squared_error: 303050.8750 - val_loss: 89617110682.7496 - val_root_mean_squared_error: 299361.1875\n",
      "Epoch 54/100\n",
      "12156/12156 [==============================] - 1s 88us/sample - loss: 90076966487.4393 - root_mean_squared_error: 300128.3438 - val_loss: 87912664324.9899 - val_root_mean_squared_error: 296500.6562\n",
      "Epoch 55/100\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 88319755911.2866 - root_mean_squared_error: 297186.4375 - val_loss: 86235808117.9255 - val_root_mean_squared_error: 293659.3438\n",
      "Epoch 56/100\n",
      "12156/12156 [==============================] - 1s 70us/sample - loss: 86564674228.1013 - root_mean_squared_error: 294218.6875 - val_loss: 84534347925.0649 - val_root_mean_squared_error: 290747.9375\n",
      "Epoch 57/100\n",
      "12156/12156 [==============================] - 1s 70us/sample - loss: 84795607315.6275 - root_mean_squared_error: 291196.8438 - val_loss: 82844349296.2408 - val_root_mean_squared_error: 287826.9375\n",
      "Epoch 58/100\n",
      "12156/12156 [==============================] - 1s 70us/sample - loss: 83027626941.6203 - root_mean_squared_error: 288145.1250 - val_loss: 81115758650.6153 - val_root_mean_squared_error: 284808.2812\n",
      "Epoch 59/100\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 81280035231.7999 - root_mean_squared_error: 285096.5312 - val_loss: 79405502149.7005 - val_root_mean_squared_error: 281789.8125\n",
      "Epoch 60/100\n",
      "12156/12156 [==============================] - 1s 70us/sample - loss: 79528201651.0062 - root_mean_squared_error: 282007.4375 - val_loss: 77712557715.6753 - val_root_mean_squared_error: 278769.7500\n",
      "Epoch 61/100\n",
      "12156/12156 [==============================] - 1s 70us/sample - loss: 77785909167.8052 - root_mean_squared_error: 278901.2188 - val_loss: 76017833287.1848 - val_root_mean_squared_error: 275713.3125\n",
      "Epoch 62/100\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 76050131814.0125 - root_mean_squared_error: 275771.9375 - val_loss: 74350890745.2415 - val_root_mean_squared_error: 272673.5938\n",
      "Epoch 63/100\n",
      "12156/12156 [==============================] - 1s 70us/sample - loss: 74338123366.2652 - root_mean_squared_error: 272650.2188 - val_loss: 72684457935.4908 - val_root_mean_squared_error: 269600.5312\n",
      "Epoch 64/100\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 72647139946.6456 - root_mean_squared_error: 269531.3125 - val_loss: 71009130789.5820 - val_root_mean_squared_error: 266475.3438\n",
      "Epoch 65/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 70973228342.3337 - root_mean_squared_error: 266408.0312 - val_loss: 69392223472.7777 - val_root_mean_squared_error: 263424.0312\n",
      "Epoch 66/100\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 69329348088.4186 - root_mean_squared_error: 263304.7188 - val_loss: 67778508956.1392 - val_root_mean_squared_error: 260343.0625\n",
      "Epoch 67/100\n",
      "12156/12156 [==============================] - 1s 79us/sample - loss: 67717570789.1280 - root_mean_squared_error: 260226.0000 - val_loss: 66217819393.9581 - val_root_mean_squared_error: 257328.2188\n",
      "Epoch 68/100\n",
      "12156/12156 [==============================] - 1s 70us/sample - loss: 66128539360.9161 - root_mean_squared_error: 257154.7188 - val_loss: 64672317994.8246 - val_root_mean_squared_error: 254307.5469\n",
      "Epoch 69/100\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 64561994891.8355 - root_mean_squared_error: 254090.5625 - val_loss: 63118099610.3706 - val_root_mean_squared_error: 251233.1562\n",
      "Epoch 70/100\n",
      "12156/12156 [==============================] - 1s 91us/sample - loss: 63022033876.5331 - root_mean_squared_error: 251041.8906 - val_loss: 61628044177.5909 - val_root_mean_squared_error: 248249.9219\n",
      "Epoch 71/100\n",
      "12156/12156 [==============================] - 1s 92us/sample - loss: 61530321788.2514 - root_mean_squared_error: 248053.0625 - val_loss: 60150633754.7180 - val_root_mean_squared_error: 245256.2500\n",
      "Epoch 72/100\n",
      "12156/12156 [==============================] - 1s 86us/sample - loss: 60096257220.4436 - root_mean_squared_error: 245145.4219 - val_loss: 58751401190.6716 - val_root_mean_squared_error: 242386.8750\n",
      "Epoch 73/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 58710417391.8263 - root_mean_squared_error: 242302.2812 - val_loss: 57397441963.2351 - val_root_mean_squared_error: 239577.6094\n",
      "Epoch 74/100\n",
      "12156/12156 [==============================] - 1s 76us/sample - loss: 57372464941.0675 - root_mean_squared_error: 239525.4844 - val_loss: 56092198412.2536 - val_root_mean_squared_error: 236837.8906\n",
      "Epoch 75/100\n",
      "12156/12156 [==============================] - 1s 77us/sample - loss: 56094588844.4357 - root_mean_squared_error: 236842.9375 - val_loss: 54860900959.8816 - val_root_mean_squared_error: 234224.0312\n",
      "Epoch 76/100\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 54898102843.4722 - root_mean_squared_error: 234303.4219 - val_loss: 53655977809.1646 - val_root_mean_squared_error: 231637.5781\n",
      "Epoch 77/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 53765138057.9822 - root_mean_squared_error: 231873.1094 - val_loss: 52571617810.0646 - val_root_mean_squared_error: 229285.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "12156/12156 [==============================] - 1s 70us/sample - loss: 52718807889.7953 - root_mean_squared_error: 229605.7812 - val_loss: 51551312472.8073 - val_root_mean_squared_error: 227049.1250\n",
      "Epoch 79/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 51717274370.2744 - root_mean_squared_error: 227414.2812 - val_loss: 50603918930.9963 - val_root_mean_squared_error: 224953.1719\n",
      "Epoch 80/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 50809783882.6351 - root_mean_squared_error: 225410.3438 - val_loss: 49724837100.7353 - val_root_mean_squared_error: 222990.6719\n",
      "Epoch 81/100\n",
      "12156/12156 [==============================] - 1s 70us/sample - loss: 49977443208.7187 - root_mean_squared_error: 223556.3906 - val_loss: 48934640073.3008 - val_root_mean_squared_error: 221211.7812\n",
      "Epoch 82/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 49223549441.5163 - root_mean_squared_error: 221863.7812 - val_loss: 48216635744.1974 - val_root_mean_squared_error: 219582.8438\n",
      "Epoch 83/100\n",
      "12156/12156 [==============================] - 1s 70us/sample - loss: 48532399468.2461 - root_mean_squared_error: 220300.7344 - val_loss: 47547589756.0523 - val_root_mean_squared_error: 218054.0781\n",
      "Epoch 84/100\n",
      "12156/12156 [==============================] - 1s 70us/sample - loss: 47921183017.1925 - root_mean_squared_error: 218909.0938 - val_loss: 47001452727.9309 - val_root_mean_squared_error: 216798.2188\n",
      "Epoch 85/100\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 47368070313.4873 - root_mean_squared_error: 217642.0625 - val_loss: 46474472559.4197 - val_root_mean_squared_error: 215579.3750\n",
      "Epoch 86/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 46897349734.7707 - root_mean_squared_error: 216557.9844 - val_loss: 46026238880.2448 - val_root_mean_squared_error: 214537.2812\n",
      "Epoch 87/100\n",
      "12156/12156 [==============================] - 1s 74us/sample - loss: 46462830161.3741 - root_mean_squared_error: 215552.4062 - val_loss: 45600624839.0900 - val_root_mean_squared_error: 213543.0625\n",
      "Epoch 88/100\n",
      "12156/12156 [==============================] - 1s 90us/sample - loss: 46092779773.3886 - root_mean_squared_error: 214692.3125 - val_loss: 45238802501.2267 - val_root_mean_squared_error: 212694.1719\n",
      "Epoch 89/100\n",
      "12156/12156 [==============================] - 1s 90us/sample - loss: 45759980145.3847 - root_mean_squared_error: 213915.7969 - val_loss: 44920379853.3432 - val_root_mean_squared_error: 211944.2812\n",
      "Epoch 90/100\n",
      "12156/12156 [==============================] - 1s 75us/sample - loss: 45475002690.8009 - root_mean_squared_error: 213248.6719 - val_loss: 44640469722.6706 - val_root_mean_squared_error: 211282.9062\n",
      "Epoch 91/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 45220444308.2593 - root_mean_squared_error: 212650.9844 - val_loss: 44388090169.2889 - val_root_mean_squared_error: 210684.8438\n",
      "Epoch 92/100\n",
      "12156/12156 [==============================] - 1s 81us/sample - loss: 44992329899.8460 - root_mean_squared_error: 212113.9375 - val_loss: 44150087875.0476 - val_root_mean_squared_error: 210119.2188\n",
      "Epoch 93/100\n",
      "12156/12156 [==============================] - 1s 70us/sample - loss: 44779142690.8746 - root_mean_squared_error: 211610.7812 - val_loss: 43940219860.7964 - val_root_mean_squared_error: 209619.2031\n",
      "Epoch 94/100\n",
      "12156/12156 [==============================] - 1s 82us/sample - loss: 44582835066.5666 - root_mean_squared_error: 211146.4844 - val_loss: 43743049132.2457 - val_root_mean_squared_error: 209148.3906\n",
      "Epoch 95/100\n",
      "12156/12156 [==============================] - 1s 93us/sample - loss: 44405619881.4873 - root_mean_squared_error: 210726.4531 - val_loss: 43554812716.5300 - val_root_mean_squared_error: 208697.9062\n",
      "Epoch 96/100\n",
      "12156/12156 [==============================] - 1s 76us/sample - loss: 44244725106.9852 - root_mean_squared_error: 210344.3125 - val_loss: 43383536309.7834 - val_root_mean_squared_error: 208287.1562\n",
      "Epoch 97/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 44083841505.8427 - root_mean_squared_error: 209961.5156 - val_loss: 43228714026.1929 - val_root_mean_squared_error: 207915.1875\n",
      "Epoch 98/100\n",
      "12156/12156 [==============================] - 1s 70us/sample - loss: 43930671910.6654 - root_mean_squared_error: 209596.4375 - val_loss: 43077889773.1142 - val_root_mean_squared_error: 207552.1406\n",
      "Epoch 99/100\n",
      "12156/12156 [==============================] - 1s 72us/sample - loss: 43808200448.5897 - root_mean_squared_error: 209304.0781 - val_loss: 42943080082.6647 - val_root_mean_squared_error: 207227.1562\n",
      "Epoch 100/100\n",
      "12156/12156 [==============================] - 1s 71us/sample - loss: 43674372145.1951 - root_mean_squared_error: 208984.1094 - val_loss: 42807372521.3244 - val_root_mean_squared_error: 206899.4375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22302b17888>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100, \n",
    "              validation_data=(X_val, y_val),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_test = np.sqrt(-keras_reg.score(X_test, y_test, verbose=0))\n",
    "rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** set up a `RandomizedSearchCV` object to explore 12 combinations from a grid of parameters on the wrapped NeuralNet `keras_reg`, using 3-fold cross validation, training the network for 20 or 100 epochs and allowing for early stopping by using the callback `keras.callbacks.EarlyStopping` with a reasonable patience (check the early-stopping API.)\n",
    "\n",
    "The range of parameters you *may* want to try in your param grid are:\n",
    " * number of hidden layers: from 1 to 3\n",
    " * number of neurons in each layer: 10, 20, 30, 40, 50\n",
    " * learning rate: a good approach for the learning rate is to use a reciprocal distribution with quantiles lower_bound = $0.0001$ and upper_bound = $0.01$. See more about reciprocal distributions here: https://en.wikipedia.org/wiki/Reciprocal_distribution. In order to set the reciprocal distribution, you can use the `reciprocal` function from the `scipy.stats` module. A simpler approach would be to pass a list of discrete values, e.g [0.0001, 0.0005, ..., 0.01]. Follow this approach if the other seems too obscure.\n",
    " * activation: 'relu', 'selu'   (see Notebook 06B)\n",
    " * kernel_initializer: 'glorot_uniform', 'lecun_normal'  (see Notebook 06B)\n",
    " \n",
    "Feel free to modify the options in this grid\n",
    "\n",
    "Check `RandomizedSearchCV` API on scikit-learn for more info.\n",
    "\n",
    "Please note that this cell will take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use `rec_dist` as defined here to set your learning rate interval\n",
    "from scipy.stats import reciprocal\n",
    "reciprocal(5e-4, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "## Write your code here\n",
    "param_grid = {\n",
    "    \"lr\": [0.0001, 0.0005, 0.001, 0.005, 0.01]\n",
    "    'hidden_layers': [10,20,30,40,50]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here you can identify the best params combination and the best score you achieved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
